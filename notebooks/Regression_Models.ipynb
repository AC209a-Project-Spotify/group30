{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we explore different regression models to predict the number of followers (log-scale) of each playlist. We use 2 sets of features and fitted 2 sets of regression models respectively.\n",
    "\n",
    "- Feature set 1: **main predictors only**\n",
    "- Feature set 2: **main predictors and interaction terms of (genre X numerical_audio_feature_avg)**\n",
    "\n",
    "For each set of features, do the following 2 steps:\n",
    "- Use main predictors only and fit **single** regression models:\n",
    "    - Linear Regression\n",
    "    - (Perform PCA on the main predictors and interaction terms set of features)\n",
    "    - RidgeCV\n",
    "    - LassoCV\n",
    "    - Random Forest Regressor\n",
    "    - Adaboost Regressor\n",
    "\n",
    "- **Stack** all fitted models on the training set together to fit a\n",
    "    - **Meta regressor 1: Weighted Average ** \n",
    "        - Gather the predicted values of all the fitted single models on the validation set\n",
    "        - Average each single model's predicted value weighted by its accuracy on the same validation set\n",
    "    \n",
    "    - **Meta regressor 2: Meta Linear Regressor ** \n",
    "        - Gather the predicted values of all the fitted single models on the validation set\n",
    "        - Fit a linear regression model on these single models' predicted values\n",
    "\n",
    "As shown in the **summary** part at the end of this notebook, **Random Forest Regressor is the best single model** and the stacked **Meta Linear Regression model is overall the best**. Comparing models with the 2 sets of features, both have overall comparable test accuracies. The interaction terms between genre and avg of numerical audio features slightly improved test accuracies for the **RidgeCV, LassoCV and weighted average meta model** but not for the other models. This suggests that some of the interaction terms are useful while others are not. Thus, the models fitted on main predictors and interaction terms are (to some extent) overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save scraped data to json file\n",
    "def dump_data(data_to_json, file):\n",
    "    # example: file = '../data/playlists_5088.json'\n",
    "    with open(file,'w') as fd:\n",
    "        json.dump(data_to_json, fd)\n",
    "\n",
    "# Load json file\n",
    "def load_data(file):\n",
    "    with open(file, 'r') as fd:\n",
    "        data_from_json = json.load(fd)\n",
    "        return data_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression models with main predictors only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take **log transform** of the skewed response variable:\n",
    "\n",
    "**`num_followers` -> `log_num_followers`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collaborative</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>track_acousticness_avg</th>\n",
       "      <th>track_acousticness_std</th>\n",
       "      <th>track_album_popularity_avg</th>\n",
       "      <th>track_album_popularity_max</th>\n",
       "      <th>track_album_popularity_std</th>\n",
       "      <th>track_artists_genres_unique</th>\n",
       "      <th>track_avg_artist_num_followers_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>track_std_artist_num_followers_std</th>\n",
       "      <th>track_std_artist_popularity_avg</th>\n",
       "      <th>track_std_artist_popularity_std</th>\n",
       "      <th>track_tempo_avg</th>\n",
       "      <th>track_tempo_std</th>\n",
       "      <th>track_time_signature_mode</th>\n",
       "      <th>track_time_signature_unique</th>\n",
       "      <th>track_valence_avg</th>\n",
       "      <th>track_valence_std</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3000606</td>\n",
       "      <td>52</td>\n",
       "      <td>0.180999</td>\n",
       "      <td>0.171120</td>\n",
       "      <td>71.673077</td>\n",
       "      <td>96</td>\n",
       "      <td>13.136445</td>\n",
       "      <td>60</td>\n",
       "      <td>1.276693e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.211661e+05</td>\n",
       "      <td>1.784248</td>\n",
       "      <td>3.081549</td>\n",
       "      <td>116.689288</td>\n",
       "      <td>25.194937</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456071</td>\n",
       "      <td>0.184214</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>69037</td>\n",
       "      <td>75</td>\n",
       "      <td>0.144201</td>\n",
       "      <td>0.160799</td>\n",
       "      <td>68.440000</td>\n",
       "      <td>100</td>\n",
       "      <td>15.511063</td>\n",
       "      <td>70</td>\n",
       "      <td>3.791621e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.539587e+06</td>\n",
       "      <td>2.114856</td>\n",
       "      <td>3.171820</td>\n",
       "      <td>114.453907</td>\n",
       "      <td>24.115022</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.555027</td>\n",
       "      <td>0.191440</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>385875</td>\n",
       "      <td>38</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.117615</td>\n",
       "      <td>72.421053</td>\n",
       "      <td>94</td>\n",
       "      <td>16.192317</td>\n",
       "      <td>44</td>\n",
       "      <td>2.319518e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.050419e+06</td>\n",
       "      <td>2.126763</td>\n",
       "      <td>2.151793</td>\n",
       "      <td>115.812500</td>\n",
       "      <td>22.759341</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526526</td>\n",
       "      <td>0.201783</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>69344</td>\n",
       "      <td>40</td>\n",
       "      <td>0.134162</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>57.025000</td>\n",
       "      <td>82</td>\n",
       "      <td>18.083815</td>\n",
       "      <td>97</td>\n",
       "      <td>2.387520e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.080303e+05</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.172753</td>\n",
       "      <td>126.490950</td>\n",
       "      <td>29.521523</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.501825</td>\n",
       "      <td>0.188804</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>15612</td>\n",
       "      <td>26</td>\n",
       "      <td>0.171635</td>\n",
       "      <td>0.229736</td>\n",
       "      <td>53.461538</td>\n",
       "      <td>54</td>\n",
       "      <td>0.498519</td>\n",
       "      <td>5</td>\n",
       "      <td>8.566853e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.278704e+04</td>\n",
       "      <td>3.346290</td>\n",
       "      <td>3.184129</td>\n",
       "      <td>126.677692</td>\n",
       "      <td>33.241999</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.658846</td>\n",
       "      <td>0.184523</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   collaborative  num_followers  num_tracks  track_acousticness_avg  \\\n",
       "0          False        3000606          52                0.180999   \n",
       "1          False          69037          75                0.144201   \n",
       "2          False         385875          38                0.116600   \n",
       "3          False          69344          40                0.134162   \n",
       "4          False          15612          26                0.171635   \n",
       "\n",
       "   track_acousticness_std  track_album_popularity_avg  \\\n",
       "0                0.171120                   71.673077   \n",
       "1                0.160799                   68.440000   \n",
       "2                0.117615                   72.421053   \n",
       "3                0.247197                   57.025000   \n",
       "4                0.229736                   53.461538   \n",
       "\n",
       "   track_album_popularity_max  track_album_popularity_std  \\\n",
       "0                          96                   13.136445   \n",
       "1                         100                   15.511063   \n",
       "2                          94                   16.192317   \n",
       "3                          82                   18.083815   \n",
       "4                          54                    0.498519   \n",
       "\n",
       "   track_artists_genres_unique  track_avg_artist_num_followers_avg  ...    \\\n",
       "0                           60                        1.276693e+06  ...     \n",
       "1                           70                        3.791621e+06  ...     \n",
       "2                           44                        2.319518e+06  ...     \n",
       "3                           97                        2.387520e+06  ...     \n",
       "4                            5                        8.566853e+04  ...     \n",
       "\n",
       "   track_std_artist_num_followers_std  track_std_artist_popularity_avg  \\\n",
       "0                        9.211661e+05                         1.784248   \n",
       "1                        1.539587e+06                         2.114856   \n",
       "2                        2.050419e+06                         2.126763   \n",
       "3                        3.080303e+05                         0.037500   \n",
       "4                        1.278704e+04                         3.346290   \n",
       "\n",
       "   track_std_artist_popularity_std  track_tempo_avg  track_tempo_std  \\\n",
       "0                         3.081549       116.689288        25.194937   \n",
       "1                         3.171820       114.453907        24.115022   \n",
       "2                         2.151793       115.812500        22.759341   \n",
       "3                         0.172753       126.490950        29.521523   \n",
       "4                         3.184129       126.677692        33.241999   \n",
       "\n",
       "   track_time_signature_mode  track_time_signature_unique  track_valence_avg  \\\n",
       "0                          4                            1           0.456071   \n",
       "1                          4                            2           0.555027   \n",
       "2                          4                            1           0.526526   \n",
       "3                          4                            2           0.501825   \n",
       "4                          4                            1           0.658846   \n",
       "\n",
       "   track_valence_std  genre  \n",
       "0           0.184214    pop  \n",
       "1           0.191440    pop  \n",
       "2           0.201783    pop  \n",
       "3           0.188804    pop  \n",
       "4           0.184523    pop  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataframe\n",
    "playlists_df_full = pd.read_csv('../../data/playlists.csv')\n",
    "playlists_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log transformation\n",
    "playlists_df_full['log_num_followers'] = np.log(list(playlists_df_full['num_followers']+1))\n",
    "\n",
    "# Dropping the original num_followers, num_tracks\n",
    "playlists_df_full.drop(['num_followers'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take **one-hot** encoding of the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the useless varaible 'collaborative'\n",
    "playlists_df_full.drop(['collaborative'], axis=1, inplace=True)\n",
    "categorical_predictors = ['genre', 'track_time_signature_mode', 'track_key_mode']\n",
    "numerical_predictors = list(set(playlists_df_full.columns.values) - set(categorical_predictors))\n",
    "\n",
    "# One-hot encode categorical features\n",
    "playlists_df_full = pd.get_dummies(playlists_df_full, prefix = categorical_predictors, \n",
    "                                         columns = categorical_predictors, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>track_acousticness_avg</th>\n",
       "      <th>track_acousticness_std</th>\n",
       "      <th>track_album_popularity_avg</th>\n",
       "      <th>track_album_popularity_max</th>\n",
       "      <th>track_album_popularity_std</th>\n",
       "      <th>track_artists_genres_unique</th>\n",
       "      <th>track_avg_artist_num_followers_avg</th>\n",
       "      <th>track_avg_artist_num_followers_std</th>\n",
       "      <th>track_avg_artist_popularity_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>track_key_mode_3</th>\n",
       "      <th>track_key_mode_4</th>\n",
       "      <th>track_key_mode_5</th>\n",
       "      <th>track_key_mode_6</th>\n",
       "      <th>track_key_mode_7</th>\n",
       "      <th>track_key_mode_8</th>\n",
       "      <th>track_key_mode_9</th>\n",
       "      <th>track_key_mode_10</th>\n",
       "      <th>track_key_mode_11</th>\n",
       "      <th>log_num_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>0.180999</td>\n",
       "      <td>0.171120</td>\n",
       "      <td>71.673077</td>\n",
       "      <td>96</td>\n",
       "      <td>13.136445</td>\n",
       "      <td>60</td>\n",
       "      <td>1.276693e+06</td>\n",
       "      <td>1.320843e+06</td>\n",
       "      <td>82.256410</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.914325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>0.144201</td>\n",
       "      <td>0.160799</td>\n",
       "      <td>68.440000</td>\n",
       "      <td>100</td>\n",
       "      <td>15.511063</td>\n",
       "      <td>70</td>\n",
       "      <td>3.791621e+06</td>\n",
       "      <td>3.658858e+06</td>\n",
       "      <td>84.684000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.142412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.117615</td>\n",
       "      <td>72.421053</td>\n",
       "      <td>94</td>\n",
       "      <td>16.192317</td>\n",
       "      <td>44</td>\n",
       "      <td>2.319518e+06</td>\n",
       "      <td>2.237652e+06</td>\n",
       "      <td>86.705263</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.863271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.134162</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>57.025000</td>\n",
       "      <td>82</td>\n",
       "      <td>18.083815</td>\n",
       "      <td>97</td>\n",
       "      <td>2.387520e+06</td>\n",
       "      <td>3.589807e+06</td>\n",
       "      <td>72.987500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.146849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>0.171635</td>\n",
       "      <td>0.229736</td>\n",
       "      <td>53.461538</td>\n",
       "      <td>54</td>\n",
       "      <td>0.498519</td>\n",
       "      <td>5</td>\n",
       "      <td>8.566853e+04</td>\n",
       "      <td>2.347853e+05</td>\n",
       "      <td>55.059341</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.655859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_tracks  track_acousticness_avg  track_acousticness_std  \\\n",
       "0          52                0.180999                0.171120   \n",
       "1          75                0.144201                0.160799   \n",
       "2          38                0.116600                0.117615   \n",
       "3          40                0.134162                0.247197   \n",
       "4          26                0.171635                0.229736   \n",
       "\n",
       "   track_album_popularity_avg  track_album_popularity_max  \\\n",
       "0                   71.673077                          96   \n",
       "1                   68.440000                         100   \n",
       "2                   72.421053                          94   \n",
       "3                   57.025000                          82   \n",
       "4                   53.461538                          54   \n",
       "\n",
       "   track_album_popularity_std  track_artists_genres_unique  \\\n",
       "0                   13.136445                           60   \n",
       "1                   15.511063                           70   \n",
       "2                   16.192317                           44   \n",
       "3                   18.083815                           97   \n",
       "4                    0.498519                            5   \n",
       "\n",
       "   track_avg_artist_num_followers_avg  track_avg_artist_num_followers_std  \\\n",
       "0                        1.276693e+06                        1.320843e+06   \n",
       "1                        3.791621e+06                        3.658858e+06   \n",
       "2                        2.319518e+06                        2.237652e+06   \n",
       "3                        2.387520e+06                        3.589807e+06   \n",
       "4                        8.566853e+04                        2.347853e+05   \n",
       "\n",
       "   track_avg_artist_popularity_avg        ...          track_key_mode_3  \\\n",
       "0                        82.256410        ...                         0   \n",
       "1                        84.684000        ...                         0   \n",
       "2                        86.705263        ...                         0   \n",
       "3                        72.987500        ...                         0   \n",
       "4                        55.059341        ...                         0   \n",
       "\n",
       "   track_key_mode_4  track_key_mode_5  track_key_mode_6  track_key_mode_7  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 1                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   track_key_mode_8  track_key_mode_9  track_key_mode_10  track_key_mode_11  \\\n",
       "0                 0                 0                  0                  1   \n",
       "1                 0                 0                  0                  0   \n",
       "2                 0                 0                  0                  1   \n",
       "3                 0                 0                  0                  0   \n",
       "4                 0                 1                  0                  0   \n",
       "\n",
       "   log_num_followers  \n",
       "0          14.914325  \n",
       "1          11.142412  \n",
       "2          12.863271  \n",
       "3          11.146849  \n",
       "4           9.655859  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change_column_order(df, col_name, index): \n",
    "    \"\"\"\n",
    "    Function to change column order in a dataframe\n",
    "    \"\"\"\n",
    "    cols = df.columns.tolist() \n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "\n",
    "# Reorder so that the response variable is the last column\n",
    "playlists_df_full = change_column_order(playlists_df_full, 'log_num_followers', len(playlists_df_full.columns))\n",
    "\n",
    "playlists_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing values in our data: False\n"
     ]
    }
   ],
   "source": [
    "print('Is there any missing values in our data: {}'.format(playlists_df_full.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data **6:1:1**\n",
    "1. **train set** for single models: 6/8 of all data\n",
    "2. **validation set** for single models & **train set for meta models**: 1/8 of all data\n",
    "3. **test set**: 1/8 of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(9001)\n",
    "msk1 = np.random.rand(len(playlists_df_full)) < 0.75\n",
    "playlists_df_train_main = playlists_df_full[msk1]\n",
    "playlists_df_nontrain_main = playlists_df_full[~msk1]\n",
    "\n",
    "msk12 = np.random.rand(len(playlists_df_nontrain_main)) < 0.5\n",
    "playlists_df_valid_main = playlists_df_nontrain_main[msk12]\n",
    "playlists_df_test_main = playlists_df_nontrain_main[~msk12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7083, 85), (7083,), (1214, 85), (1214,), (1133, 85), (1133,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build predictors & response\n",
    "X_train_main = playlists_df_train_main.iloc[:,:-1]\n",
    "X_valid_main = playlists_df_valid_main.iloc[:,:-1]\n",
    "X_test_main = playlists_df_test_main.iloc[:,:-1]\n",
    "\n",
    "y_train = playlists_df_train_main['log_num_followers']\n",
    "y_valid = playlists_df_valid_main['log_num_followers']\n",
    "y_test = playlists_df_test_main['log_num_followers']\n",
    "\n",
    "X_train_main.shape, y_train.shape, X_valid_main.shape, y_valid.shape, X_test_main.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that have only 0, and **standardize** numerical variables using **train set's mean and std**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in X_train_main.columns:\n",
    "    if (X_train_main[col] == 0).all():\n",
    "        X_train_main.drop(col, axis=1, inplace=True)\n",
    "    else:\n",
    "        # Standardize a numerical variable\n",
    "        if not np.logical_or((X_train_main[col]==0), ((X_train_main[col]==1))).all():\n",
    "            mean_train = X_train_main[col].mean()\n",
    "            std_train = X_train_main[col].std()\n",
    "            X_train_main[col] = (X_train_main[col] - mean_train) / std_train\n",
    "            X_valid_main[col] = (X_valid_main[col] - mean_train) / std_train\n",
    "            X_test_main[col] = (X_test_main[col] - mean_train) / std_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit & Save model\n",
    "sim_lin_main = LinearRegression().fit(X_train_main, y_train)\n",
    "joblib.dump(sim_lin_main, '../../fitted_models/sim_lin_main.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Linear Regression with all main predictors only --\n",
      "Training R^2:  0.263847739771\n",
      "Test R^2:  0.252153441084\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "sim_lin_main = joblib.load('../../fitted_models/sim_lin_main.pkl') \n",
    "print('-- Linear Regression with all main predictors only --')\n",
    "print('Training R^2: ', sim_lin_main.score(X_train_main, y_train))\n",
    "print('Test R^2: ', sim_lin_main.score(X_test_main, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
    "ridge_cv_main = RidgeCV(alphas=lambdas, fit_intercept=True).fit(X_train_main, y_train)\n",
    "joblib.dump(ridge_cv_main, '../../fitted_models/ridge_cv_main.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- RidgeCV (best alpha = 10.0) with all main predictors only --\n",
      "Training R^2: 0.263451109837063\n",
      "Test R^2: 0.25052396982949465\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model\n",
    "ridge_cv_main = joblib.load('../../fitted_models/ridge_cv_main.pkl') \n",
    "ridge_r2_train_main = ridge_cv_main.score(X_train_main, y_train)\n",
    "ridge_r2_test_main = ridge_cv_main.score(X_test_main, y_test)\n",
    "\n",
    "print('-- RidgeCV (best alpha = {}) with all main predictors only --'.format(ridge_cv_main.alpha_))\n",
    "print(\"Training R^2: {}\".format(ridge_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(ridge_r2_test_main))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
    "lasso_cv_main = LassoCV(alphas=lambdas, fit_intercept=True).fit(X_train_main, y_train)\n",
    "joblib.dump(lasso_cv_main, '../../fitted_models/lasso_cv_main.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- LassoCV (best alpha = 0.01) with all main predictors only --\n",
      "Training R^2: 0.2556596987903933\n",
      "Test R^2: 0.24914685865189712\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model\n",
    "lasso_cv_main = joblib.load('../../fitted_models/lasso_cv_main.pkl') \n",
    "lasso_r2_train_main = lasso_cv_main.score(X_train_main, y_train)\n",
    "lasso_r2_test_main = lasso_cv_main.score(X_test_main, y_test)\n",
    "\n",
    "print('-- LassoCV (best alpha = {}) with all main predictors only --'.format(lasso_cv_main.alpha_))\n",
    "print(\"Training R^2: {}\".format(lasso_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(lasso_r2_test_main))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([[4, 8, 16, 32, 64, 128, 256], [0.1, 0.3, 0.5, 0.7, 0.9]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_params = OrderedDict(\n",
    "    n_estimators = [2**(i+2) for i in np.arange(7)],\n",
    "    max_features = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    ")\n",
    "RF_params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use 5-fold validation to find the optimal n_estimators and max_features for Random Forest Regression\n",
    "cv_scores_RF_main = []\n",
    "params_dict_RF_main = {}\n",
    "\n",
    "for i, (n, f) in enumerate(product(*RF_params.values())):\n",
    "    params_dict_RF_main[i] = (n, f)\n",
    "    \n",
    "    # Cross Validation on Random Forest Classifier\n",
    "    RF_main = RandomForestRegressor(oob_score=False, n_estimators=n, max_features=f, n_jobs=-1, random_state=22)\n",
    "    scores = cross_val_score(RF_main, X_train_main, y_train, cv=5, scoring='r2')\n",
    "    cv_scores_RF_main.append(scores.mean())\n",
    "\n",
    "# Get the optimal set of parameters of the Random Forest Regressor\n",
    "idx_optimal = np.argmax(cv_scores_RF_main)\n",
    "optimal_params_RF_main = params_dict_RF_main[idx_optimal]\n",
    "print('-- Random Forest Regression --')\n",
    "print('Maximum R^2 validation score = {}'.format(max(cv_scores_RF_main)))\n",
    "print('Optimal n_estimators = {}'.format(optimal_params_RF_main[0]))\n",
    "print('Optimal max_features = {}'.format(optimal_params_RF_main[1]))\n",
    "\n",
    "# Fit the optimal RF\n",
    "RF_best_main = RandomForestRegressor(oob_score=False, n_estimators=optimal_params_RF_main[0], \n",
    "                                     max_features=optimal_params_RF_main[1], n_jobs=-1, \n",
    "                                     random_state=22).fit(X_train_main, y_train)\n",
    "RF_best_r2_train_main = RF_best_main.score(X_train_main, y_train)\n",
    "RF_best_r2_test_main = RF_best_main.score(X_test_main, y_test)\n",
    "print('-- Best Random Forest Regression --')\n",
    "print(\"Training R^2: {}\".format(RF_best_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(RF_best_r2_test_main))\n",
    "\n",
    "# Dump fitted model to disk\n",
    "joblib.dump(RF_best_main, '../../fitted_models/RF_best_main.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model to reproduce results directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best Random Forest Regression with all main predictors only --\n",
      "Training R^2: 0.9263072080770891\n",
      "Test R^2: 0.48156931235472966\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "RF_best_main = joblib.load('../../fitted_models/RF_best_main.pkl') \n",
    "RF_best_r2_train_main = RF_best_main.score(X_train_main, y_train)\n",
    "RF_best_r2_test_main = RF_best_main.score(X_test_main, y_test)\n",
    "print('-- Best Random Forest Regression with all main predictors only --')\n",
    "print(\"Training R^2: {}\".format(RF_best_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(RF_best_r2_test_main))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([[2, 4, 6, 8], [4, 8, 16, 32, 64, 128, 256]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_params = OrderedDict(\n",
    "    base_depths = [2, 4, 6, 8],\n",
    "    n_estimators = [2**(i+2) for i in np.arange(7)]\n",
    ")\n",
    "ab_params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use 5-fold CV to choose max_depth & n_estimators in AdaBoost Regressor\n",
    "l_rate = 0.05\n",
    "params_dict_ab_main = {}\n",
    "cv_scores_ab_main = []\n",
    "for i, (d, n) in enumerate(product(*ab_params.values())):\n",
    "    params_dict_ab_main[i] = (d, n)\n",
    "    ab_main = AdaBoostRegressor(DecisionTreeRegressor(max_depth=d, random_state=22), n_estimators=n, \n",
    "                                learning_rate=l_rate, random_state=22)\n",
    "    scores = cross_val_score(ab_main, X_train_main, y_train, cv=5, scoring='r2')\n",
    "    cv_scores_ab_main.append(scores.mean())\n",
    "\n",
    "\n",
    "# Get the optimal set of parameters of the Random Forest Regressor\n",
    "idx_optimal = np.argmax(cv_scores_ab_main)\n",
    "optimal_params_ab_main = params_dict_ab_main[idx_optimal]\n",
    "print('-- AdaBoost Regression --')\n",
    "print('Maximum R^2 cv score = {}'.format(max(cv_scores_ab_main)))\n",
    "print('Optimal base tree max_depth = {}'.format(optimal_params_ab_main[0]))\n",
    "print('Optimal n_estimators = {}'.format(optimal_params_ab_main[1]))\n",
    "\n",
    "\n",
    "# Fit the best Adaboost Regressor\n",
    "ab_best_main = AdaBoostRegressor(DecisionTreeRegressor(max_depth=optimal_params_ab_main[0], random_state=22), \n",
    "                                 n_estimators=optimal_params_ab_main[1], learning_rate=l_rate, \n",
    "                                 random_state=22).fit(X_train_main, y_train)\n",
    "ab_best_r2_train_main = ab_best_main.score(X_train_main, y_train)\n",
    "ab_best_r2_test_main = ab_best_main.score(X_test_main, y_test)\n",
    "print('-- Best AdaBoost Regression --')\n",
    "print(\"Training R^2: {}\".format(ab_best_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(ab_best_r2_test_main))\n",
    "\n",
    "# Dump fitted model to disk\n",
    "joblib.dump(ab_best_main, '../../fitted_models/ab_best_main.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model to reproduce results directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best AdaBoost Regression --\n",
      "Training R^2: 0.6574644836867659\n",
      "Test R^2: 0.4194601631510584\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "ab_best_main = joblib.load('../../fitted_models/ab_best_main.pkl') \n",
    "ab_best_r2_train_main = ab_best_main.score(X_train_main, y_train)\n",
    "ab_best_r2_test_main = ab_best_main.score(X_test_main, y_test)\n",
    "print('-- Best AdaBoost Regression --')\n",
    "print(\"Training R^2: {}\".format(ab_best_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(ab_best_r2_test_main))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Model: Weighted Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Meta model 1: Weighted Avg with main predictors only --\n",
      "Valid R^2: 0.4051594155555923\n",
      "Test R^2: 0.41065615616702467\n"
     ]
    }
   ],
   "source": [
    "prefix = '../../fitted_models/'\n",
    "suffix = '.pkl'\n",
    "models_main = ['sim_lin_main', 'ridge_cv_main', 'lasso_cv_main', 'RF_best_main', 'ab_best_main']\n",
    "\n",
    "# Record model's r2 score and predicted results on validation set\n",
    "weights_main = np.zeros((len(models_main),))\n",
    "preds_main_valid = np.zeros((y_valid.shape[0], len(models_main)))\n",
    "preds_main_test = np.zeros((y_test.shape[0], len(models_main)))\n",
    "for i, name in enumerate(models_main):\n",
    "    model_name = prefix + name + suffix\n",
    "    model = joblib.load(model_name) \n",
    "    weights_main[i] = model.score(X_valid_main, y_valid)\n",
    "    preds_main_valid[:, i] = model.predict(X_valid_main)\n",
    "    preds_main_test[:, i] = model.predict(X_test_main)\n",
    "\n",
    "weights_main = weights_main/np.sum(weights_main)\n",
    "meta_pred_main_valid = np.average(preds_main_valid, axis=1, weights=weights_main)\n",
    "meta_pred_main_test = np.average(preds_main_test, axis=1, weights=weights_main)\n",
    "\n",
    "# Print model performance\n",
    "meta_r2_valid_main = r2_score(y_valid, meta_pred_main_valid)\n",
    "meta_r2_test_main = r2_score(y_test, meta_pred_main_test)\n",
    "print('-- Meta model 1: Weighted Avg with main predictors only --')\n",
    "print(\"Valid R^2: {}\".format(meta_r2_valid_main))\n",
    "print(\"Test R^2: {}\".format(meta_r2_test_main))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Model: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Meta model 2: Linear Regression with main predictors only --\n",
      "Train R^2: 0.48592344342771787\n",
      "Test R^2: 0.4965343020024535\n"
     ]
    }
   ],
   "source": [
    "# Record model's predicted results on validation set as the train set for the meta regressor\n",
    "meta_X_train_main = np.zeros((y_valid.shape[0], len(models_main)))\n",
    "meta_X_test_main = np.zeros((y_test.shape[0], len(models_main)))\n",
    "for i, name in enumerate(models_main):\n",
    "    model_name = prefix + name + suffix\n",
    "    model = joblib.load(model_name) \n",
    "    meta_X_train_main[:, i] = model.predict(X_valid_main)\n",
    "    meta_X_test_main[:, i] = model.predict(X_test_main)\n",
    "\n",
    "meta_reg_main = LinearRegression().fit(meta_X_train_main, y_valid)\n",
    "joblib.dump(meta_reg_main, '../../fitted_models/meta_reg_main.pkl') # Dump fitted model to disk\n",
    "\n",
    "# Load fitted model to reproduce results\n",
    "meta_reg_main = joblib.load('../../fitted_models/meta_reg_main.pkl') \n",
    "print('-- Meta model 2: Linear Regression with main predictors only --')\n",
    "print(\"Train R^2: {}\".format(meta_reg_main.score(meta_X_train_main, y_valid)))\n",
    "print(\"Test R^2: {}\".format(meta_reg_main.score(meta_X_test_main, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression models on main predictors & interaction terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add interaction terms between **genres** and the **numerical audio features' average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_features_avg = ['track_acousticness_avg', 'track_album_popularity_avg', 'track_danceability_avg',\n",
    "                    'track_duration_ms_avg', 'track_energy_avg', 'track_explicit_avg', \n",
    "                    'track_instrumentalness_avg', 'track_liveness_avg', 'track_loudness_avg', 'track_mode_avg', \n",
    "                    'track_speechiness_avg', 'track_tempo_avg', 'track_valence_avg']\n",
    "genres = ['genre_blues', 'genre_classical', 'genre_country', 'genre_dance',\n",
    "       'genre_edm', 'genre_elect', 'genre_folk', 'genre_funk', 'genre_hip hop',\n",
    "       'genre_house', 'genre_indie', 'genre_indie pop', 'genre_jazz',\n",
    "       'genre_korean pop', 'genre_mellow', 'genre_metal', 'genre_other',\n",
    "       'genre_pop', 'genre_pop christmas', 'genre_pop rap', 'genre_punk',\n",
    "       'genre_r&b', 'genre_rap', 'genre_reggae', 'genre_rock', 'genre_soul',]\n",
    "\n",
    "cross_terms = audio_features_avg + genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>track_acousticness_avg</th>\n",
       "      <th>track_acousticness_std</th>\n",
       "      <th>track_album_popularity_avg</th>\n",
       "      <th>track_album_popularity_max</th>\n",
       "      <th>track_album_popularity_std</th>\n",
       "      <th>track_artists_genres_unique</th>\n",
       "      <th>track_avg_artist_num_followers_avg</th>\n",
       "      <th>track_avg_artist_num_followers_std</th>\n",
       "      <th>track_avg_artist_popularity_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>track_valence_avg_X_genre_pop</th>\n",
       "      <th>track_valence_avg_X_genre_pop christmas</th>\n",
       "      <th>track_valence_avg_X_genre_pop rap</th>\n",
       "      <th>track_valence_avg_X_genre_punk</th>\n",
       "      <th>track_valence_avg_X_genre_r&amp;b</th>\n",
       "      <th>track_valence_avg_X_genre_rap</th>\n",
       "      <th>track_valence_avg_X_genre_reggae</th>\n",
       "      <th>track_valence_avg_X_genre_rock</th>\n",
       "      <th>track_valence_avg_X_genre_soul</th>\n",
       "      <th>log_num_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>0.180999</td>\n",
       "      <td>0.171120</td>\n",
       "      <td>71.673077</td>\n",
       "      <td>96</td>\n",
       "      <td>13.136445</td>\n",
       "      <td>60</td>\n",
       "      <td>1.276693e+06</td>\n",
       "      <td>1.320843e+06</td>\n",
       "      <td>82.256410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.914325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>0.144201</td>\n",
       "      <td>0.160799</td>\n",
       "      <td>68.440000</td>\n",
       "      <td>100</td>\n",
       "      <td>15.511063</td>\n",
       "      <td>70</td>\n",
       "      <td>3.791621e+06</td>\n",
       "      <td>3.658858e+06</td>\n",
       "      <td>84.684000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.142412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.117615</td>\n",
       "      <td>72.421053</td>\n",
       "      <td>94</td>\n",
       "      <td>16.192317</td>\n",
       "      <td>44</td>\n",
       "      <td>2.319518e+06</td>\n",
       "      <td>2.237652e+06</td>\n",
       "      <td>86.705263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.863271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.134162</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>57.025000</td>\n",
       "      <td>82</td>\n",
       "      <td>18.083815</td>\n",
       "      <td>97</td>\n",
       "      <td>2.387520e+06</td>\n",
       "      <td>3.589807e+06</td>\n",
       "      <td>72.987500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.146849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>0.171635</td>\n",
       "      <td>0.229736</td>\n",
       "      <td>53.461538</td>\n",
       "      <td>54</td>\n",
       "      <td>0.498519</td>\n",
       "      <td>5</td>\n",
       "      <td>8.566853e+04</td>\n",
       "      <td>2.347853e+05</td>\n",
       "      <td>55.059341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.655859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 424 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_tracks  track_acousticness_avg  track_acousticness_std  \\\n",
       "0          52                0.180999                0.171120   \n",
       "1          75                0.144201                0.160799   \n",
       "2          38                0.116600                0.117615   \n",
       "3          40                0.134162                0.247197   \n",
       "4          26                0.171635                0.229736   \n",
       "\n",
       "   track_album_popularity_avg  track_album_popularity_max  \\\n",
       "0                   71.673077                          96   \n",
       "1                   68.440000                         100   \n",
       "2                   72.421053                          94   \n",
       "3                   57.025000                          82   \n",
       "4                   53.461538                          54   \n",
       "\n",
       "   track_album_popularity_std  track_artists_genres_unique  \\\n",
       "0                   13.136445                           60   \n",
       "1                   15.511063                           70   \n",
       "2                   16.192317                           44   \n",
       "3                   18.083815                           97   \n",
       "4                    0.498519                            5   \n",
       "\n",
       "   track_avg_artist_num_followers_avg  track_avg_artist_num_followers_std  \\\n",
       "0                        1.276693e+06                        1.320843e+06   \n",
       "1                        3.791621e+06                        3.658858e+06   \n",
       "2                        2.319518e+06                        2.237652e+06   \n",
       "3                        2.387520e+06                        3.589807e+06   \n",
       "4                        8.566853e+04                        2.347853e+05   \n",
       "\n",
       "   track_avg_artist_popularity_avg        ...          \\\n",
       "0                        82.256410        ...           \n",
       "1                        84.684000        ...           \n",
       "2                        86.705263        ...           \n",
       "3                        72.987500        ...           \n",
       "4                        55.059341        ...           \n",
       "\n",
       "   track_valence_avg_X_genre_pop  track_valence_avg_X_genre_pop christmas  \\\n",
       "0                       0.456071                                      0.0   \n",
       "1                       0.555027                                      0.0   \n",
       "2                       0.526526                                      0.0   \n",
       "3                       0.501825                                      0.0   \n",
       "4                       0.658846                                      0.0   \n",
       "\n",
       "   track_valence_avg_X_genre_pop rap  track_valence_avg_X_genre_punk  \\\n",
       "0                                0.0                             0.0   \n",
       "1                                0.0                             0.0   \n",
       "2                                0.0                             0.0   \n",
       "3                                0.0                             0.0   \n",
       "4                                0.0                             0.0   \n",
       "\n",
       "   track_valence_avg_X_genre_r&b  track_valence_avg_X_genre_rap  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                            0.0                            0.0   \n",
       "\n",
       "   track_valence_avg_X_genre_reggae  track_valence_avg_X_genre_rock  \\\n",
       "0                               0.0                             0.0   \n",
       "1                               0.0                             0.0   \n",
       "2                               0.0                             0.0   \n",
       "3                               0.0                             0.0   \n",
       "4                               0.0                             0.0   \n",
       "\n",
       "   track_valence_avg_X_genre_soul  log_num_followers  \n",
       "0                             0.0          14.914325  \n",
       "1                             0.0          11.142412  \n",
       "2                             0.0          12.863271  \n",
       "3                             0.0          11.146849  \n",
       "4                             0.0           9.655859  \n",
       "\n",
       "[5 rows x 424 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of the original playlists dataframe\n",
    "playlists_df_interaction = deepcopy(playlists_df_full)\n",
    "\n",
    "# Generate 2-way interaction terms\n",
    "for feature in audio_features_avg:\n",
    "    for genre in genres:\n",
    "        playlists_df_interaction[feature+'_X_'+genre] = playlists_df_full[feature] * playlists_df_full[genre]\n",
    "\n",
    "playlists_df_interaction = change_column_order(playlists_df_interaction, 'log_num_followers', len(playlists_df_interaction.columns))\n",
    "playlists_df_interaction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data **6:1:1**\n",
    "1. **train set** for single models: 6/8 of all data\n",
    "2. **validation set** for single models & **train set for meta models**: 1/8 of all data\n",
    "3. **test set**: 1/8 of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into train & test set\n",
    "np.random.seed(9001)\n",
    "msk2 = np.random.rand(len(playlists_df_interaction)) < 0.75\n",
    "playlists_df_train_int = playlists_df_interaction[msk2]\n",
    "playlists_df_nontrain_int = playlists_df_interaction[~msk2]\n",
    "\n",
    "msk22 = np.random.rand(len(playlists_df_nontrain_int)) < 0.5\n",
    "playlists_df_valid_int = playlists_df_nontrain_int[msk22]\n",
    "playlists_df_test_int = playlists_df_nontrain_int[~msk22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7083, 423), (7083,), (1214, 423), (1214,), (1133, 423), (1133,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build predictors & response\n",
    "X_train_int = playlists_df_train_int.iloc[:,:-1]\n",
    "X_valid_int = playlists_df_valid_int.iloc[:,:-1]\n",
    "X_test_int = playlists_df_test_int.iloc[:,:-1]\n",
    "\n",
    "X_train_int.shape, y_train.shape, X_valid_int.shape, y_valid.shape, X_test_int.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that have only 0 and **standardize** numerical variables using **train set's mean and std**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in X_train_int.columns:\n",
    "    if (X_train_int[col] == 0).all():\n",
    "        X_train_int.drop(col, axis=1, inplace=True)\n",
    "    else:\n",
    "        # Standardize a numerical variable\n",
    "        if not np.logical_or((X_train_int[col]==0), ((X_train_int[col]==1))).all():\n",
    "            mean_train = X_train_int[col].mean()\n",
    "            std_train = X_train_int[col].std()\n",
    "            X_train_int[col] = (X_train_int[col] - mean_train) / std_train\n",
    "            X_valid_int[col] = (X_valid_int[col] - mean_train) / std_train\n",
    "            X_test_int[col] = (X_test_int[col] - mean_train) / std_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit & Save Model\n",
    "sim_lin_int = LinearRegression().fit(X_train_int, y_train)\n",
    "joblib.dump(sim_lin_int, '../../fitted_models/sim_lin_int.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Regression with all predictors and interaction terms --\n",
      "Training R^2:  0.324099629417\n",
      "Test R^2:  0.246580040621\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "sim_lin_int = joblib.load('../../fitted_models/sim_lin_int.pkl') \n",
    "print('-- Regression with all predictors and interaction terms --')\n",
    "print('Training R^2: ', sim_lin_int.score(X_train_int, y_train))\n",
    "print('Test R^2: ', sim_lin_int.score(X_test_int, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA on main predictors & their interaction terms\n",
    "Use 5-Fold cross-validation to find the best n_components of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best n_components for PCA is 188\n"
     ]
    }
   ],
   "source": [
    "n_pca = 200\n",
    "r2_valid_cv = np.zeros((n_pca, 5))\n",
    "\n",
    "fold_ctr = 0\n",
    "for itrain, ivalid in KFold(n_splits=5, shuffle=True, random_state=9001).split(X_train_int.index):\n",
    "    # in general though its good for creating consistent psets, don't put seeds into kfold split\n",
    "    X_train_cv = X_train_int.iloc[itrain,:]\n",
    "    y_train_cv = y_train.iloc[itrain]\n",
    "    X_valid_cv = X_train_int.iloc[ivalid,:]\n",
    "    y_valid_cv = y_train.iloc[ivalid]\n",
    "    \n",
    "    # pca\n",
    "    pca = PCA()\n",
    "    pca.fit(X_train_cv)\n",
    "    X_train_pca_cv = pca.transform(X_train_cv)\n",
    "    X_valid_pca_cv = pca.transform(X_valid_cv)\n",
    "    \n",
    "    for comp in range(1, n_pca+1):\n",
    "        linear_cv = LinearRegression().fit(X_train_pca_cv[:,:comp], y_train_cv) # fit model\n",
    "        r2_valid_cv[comp-1,fold_ctr] = linear_cv.score(X_valid_pca_cv[:,:comp], y_valid_cv) # get valid r2 score\n",
    "        \n",
    "    fold_ctr += 1\n",
    "\n",
    "\n",
    "scores_valid = np.mean(r2_valid_cv, axis=1)[1:]\n",
    "best_n = np.argmax(scores_valid)\n",
    "print('The best n_components for PCA is {}'.format(best_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Linear Regression on main predictors & interaction terms ' best PCA(n_components=188) --\n",
      "Training R^2: 0.2637031949094367\n",
      "Test R^2: 0.20381245149309746\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train_int)\n",
    "\n",
    "X_train_int_pca_best = pca.transform(X_train_int)[:,:best_n]\n",
    "X_test_int_pca_best = pca.transform(X_test_int)[:,:best_n]\n",
    "\n",
    "linear_pca_best = LinearRegression().fit(X_train_int_pca_best, y_train)\n",
    "score_train_pca_best = linear_pca_best.score(X_train_int_pca_best, y_train)\n",
    "score_test_pca_best = linear_pca_best.score(X_test_int_pca_best, y_test)\n",
    "\n",
    "print('-- Linear Regression on main predictors & interaction terms \\' best PCA(n_components={}) --'.format(best_n))\n",
    "print(\"Training R^2: {}\".format(score_train_pca_best))\n",
    "print(\"Test R^2: {}\".format(score_test_pca_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
    "ridge_cv_int = RidgeCV(alphas=lambdas, fit_intercept=True).fit(X_train_int, y_train)\n",
    "joblib.dump(ridge_cv_int, '../../fitted_models/ridge_cv_int.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- RidgeCV (best alpha = 100.0) with main predictors & interaction terms --\n",
      "Training R^2: 0.2996521645411735\n",
      "Test R^2: 0.25243054110669527\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model\n",
    "ridge_cv_int = joblib.load('../../fitted_models/ridge_cv_int.pkl') \n",
    "ridge_r2_train_int = ridge_cv_int.score(X_train_int, y_train)\n",
    "ridge_r2_test_int = ridge_cv_int.score(X_test_int, y_test)\n",
    "\n",
    "print('-- RidgeCV (best alpha = {}) with main predictors & interaction terms --'.format(ridge_cv_int.alpha_))\n",
    "print(\"Training R^2: {}\".format(ridge_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(ridge_r2_test_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
    "lasso_cv_int = LassoCV(alphas=lambdas, fit_intercept=True).fit(X_train_int, y_train)\n",
    "joblib.dump(lasso_cv_int, '../../fitted_models/lasso_cv_int.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- LassoCV w/ (best alpha = 0.01) with main predictors & interaction terms --\n",
      "Training R^2: 0.2875042397561971\n",
      "Test R^2: 0.2689411261878084\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model\n",
    "lasso_cv_int = joblib.load('../../fitted_models/lasso_cv_int.pkl') \n",
    "lasso_r2_train_int = lasso_cv_int.score(X_train_int, y_train)\n",
    "lasso_r2_test_int = lasso_cv_int.score(X_test_int, y_test)\n",
    "\n",
    "print('-- LassoCV w/ (best alpha = {}) with main predictors & interaction terms --'.format(lasso_cv_int.alpha_))\n",
    "print(\"Training R^2: {}\".format(lasso_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(lasso_r2_test_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use r2 on validation set to find the optimal n_estimators and max_features\n",
    "cv_scores_RF_int = []\n",
    "params_dict_RF_int = {}\n",
    "\n",
    "for i, (n, f) in enumerate(product(*RF_params.values())):\n",
    "    params_dict_RF_int[i] = (n, f)\n",
    "    \n",
    "    # Cross Validation on Random Forest Classifier\n",
    "    RF_int = RandomForestRegressor(oob_score=False, n_estimators=n, max_features=f, n_jobs=-1, random_state=22)\n",
    "    scores = cross_val_score(RF_int, X_train_main, y_train, cv=5, scoring='r2')\n",
    "    cv_scores_RF_int.append(scores.mean())\n",
    "\n",
    "# Get the optimal set of parameters of the Random Forest Regressor\n",
    "idx_optimal = np.argmax(cv_scores_RF_int)\n",
    "optimal_params_RF_int = params_dict_RF_int[idx_optimal]\n",
    "print('-- Random Forest Regression with main predictors & interaction terms --')\n",
    "print('Maximum R^2 validation score = {}'.format(max(cv_scores_RF_int)))\n",
    "print('Optimal n_estimators = {}'.format(optimal_params_RF_int[0]))\n",
    "print('Optimal max_features = {}'.format(optimal_params_RF_int[1]))\n",
    "\n",
    "# Fit the best RF\n",
    "RF_best_int = RandomForestRegressor(oob_score=False, n_estimators=optimal_params_RF_int[0], \n",
    "                                     max_features=optimal_params_RF_int[1], n_jobs=-1, \n",
    "                                     random_state=22).fit(X_train_int, y_train)\n",
    "RF_best_r2_train_int = RF_best_int.score(X_train_int, y_train)\n",
    "RF_best_r2_test_int = RF_best_int.score(X_test_int, y_test)\n",
    "print('-- Best Random Forest Regression w/ interaction terms --')\n",
    "print(\"Training R^2: {}\".format(RF_best_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(RF_best_r2_test_int))\n",
    "\n",
    "# Dump fitted model to disk\n",
    "joblib.dump(RF_best_int, '../../fitted_models/RF_best_int.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model to reproduce results directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best Random Forest Regression with main predictors & interaction terms --\n",
      "Training R^2: 0.9257887738410054\n",
      "Test R^2: 0.47591913127397234\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "RF_best_int = joblib.load('../../fitted_models/RF_best_int.pkl') \n",
    "RF_best_r2_train_int = RF_best_int.score(X_train_int, y_train)\n",
    "RF_best_r2_test_int = RF_best_int.score(X_test_int, y_test)\n",
    "print('-- Best Random Forest Regression with main predictors & interaction terms --')\n",
    "print(\"Training R^2: {}\".format(RF_best_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(RF_best_r2_test_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use 5-fold CV to choose max_depth & n_estimators in AdaBoost Regressor\n",
    "l_rate = 0.05\n",
    "params_dict_ab_int = {}\n",
    "cv_scores_ab_int = []\n",
    "for i, (d, n) in enumerate(product(*ab_params.values())):\n",
    "    params_dict_ab_int[i] = (d, n)\n",
    "    ab_main = AdaBoostRegressor(DecisionTreeRegressor(max_depth=d, random_state=22), n_estimators=n, \n",
    "                                learning_rate=l_rate, random_state=22)\n",
    "    scores = cross_val_score(ab_main, X_train_int, y_train, cv=5, scoring='r2')\n",
    "    cv_scores_ab_int.append(scores.mean())\n",
    "\n",
    "# Get the optimal set of parameters of the AdaBoost Regressor\n",
    "idx_optimal = np.argmax(cv_scores_ab_int)\n",
    "optimal_params_ab_int = params_dict_ab_int[idx_optimal]\n",
    "print('-- AdaBoost Regression with main predictors & interaction terms --')\n",
    "print('Maximum R^2 validation score = {}'.format(max(cv_scores_ab_int)))\n",
    "print('Optimal base tree max_depth = {}'.format(optimal_params_ab_int[0]))\n",
    "print('Optimal n_estimators = {}'.format(optimal_params_ab_int[1]))\n",
    "\n",
    "# Fit the best Adaboost regressor\n",
    "ab_best_int = AdaBoostRegressor(DecisionTreeRegressor(max_depth=optimal_params_ab_int[0], random_state=22), \n",
    "                                 n_estimators=optimal_params_ab_int[1], learning_rate=l_rate, \n",
    "                                 random_state=22).fit(X_train_int, y_train)\n",
    "\n",
    "ab_best_r2_train_int = ab_best_int.score(X_train_int, y_train)\n",
    "ab_best_r2_test_int = ab_best_int.score(X_test_int, y_test)\n",
    "print('-- Best AdaBoost Regression with main predictors & interaction terms --')\n",
    "print(\"Training R^2: {}\".format(ab_best_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(ab_best_r2_test_int))\n",
    "\n",
    "# Dump fitted model to disk\n",
    "joblib.dump(ab_best_int, '../../fitted_models/ab_best_int.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model to reproduce results directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best AdaBoost Regression with main predictors & interaction terms --\n",
      "Training R^2: 0.6450367936426891\n",
      "Test R^2: 0.4128596865435953\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "ab_best_int = joblib.load('../../fitted_models/ab_best_int.pkl') \n",
    "ab_best_r2_train_int = ab_best_int.score(X_train_int, y_train)\n",
    "ab_best_r2_test_int = ab_best_int.score(X_test_int, y_test)\n",
    "print('-- Best AdaBoost Regression with main predictors & interaction terms --')\n",
    "print(\"Training R^2: {}\".format(ab_best_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(ab_best_r2_test_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Model: Weighted Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Meta model 1: Weighted Avg with main predictors & interaction terms --\n",
      "Valid (Meta Train) R^2: 0.40621785748120054\n",
      "Test R^2: 0.4157773596959048\n"
     ]
    }
   ],
   "source": [
    "prefix = '../../fitted_models/'\n",
    "suffix = '.pkl'\n",
    "models_int = ['sim_lin_int', 'ridge_cv_int', 'lasso_cv_int', 'RF_best_int', 'ab_best_int']\n",
    "\n",
    "# Record model's r2 score and predicted results on validation set\n",
    "weights_int = np.zeros((len(models_int),))\n",
    "preds_int_valid = np.zeros((y_valid.shape[0], len(models_int)))\n",
    "preds_int_test = np.zeros((y_test.shape[0], len(models_int)))\n",
    "for i, name in enumerate(models_int):\n",
    "    model_name = prefix + name + suffix\n",
    "    model = joblib.load(model_name) \n",
    "    weights_int[i] = model.score(X_valid_int, y_valid)\n",
    "    preds_int_valid[:, i] = model.predict(X_valid_int)\n",
    "    preds_int_test[:, i] = model.predict(X_test_int)\n",
    "\n",
    "weights_int = weights_int/np.sum(weights_int)\n",
    "meta_pred_int_valid = np.average(preds_int_valid, axis=1, weights=weights_int)\n",
    "meta_pred_int_test = np.average(preds_int_test, axis=1, weights=weights_int)\n",
    "\n",
    "meta_r2_valid_int = r2_score(y_valid, meta_pred_int_valid)\n",
    "meta_r2_test_int = r2_score(y_test, meta_pred_int_test)\n",
    "print('-- Meta model 1: Weighted Avg with main predictors & interaction terms --')\n",
    "print(\"Valid (Meta Train) R^2: {}\".format(meta_r2_valid_int))\n",
    "print(\"Test R^2: {}\".format(meta_r2_test_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Model: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Meta model 2: Linear Regression with main predictors & interaction terms --\n",
      "Train R^2: 0.4849953986455844\n",
      "Test R^2: 0.49444420329210315\n"
     ]
    }
   ],
   "source": [
    "# Record model's predicted results on validation set as the train set for the meta regressor\n",
    "meta_X_train_int = np.zeros((y_valid.shape[0], len(models_int)))\n",
    "meta_X_test_int = np.zeros((y_test.shape[0], len(models_int)))\n",
    "for i, name in enumerate(models_int):\n",
    "    model_name = prefix + name + suffix\n",
    "    model = joblib.load(model_name) \n",
    "    meta_X_train_int[:, i] = model.predict(X_valid_int)\n",
    "    meta_X_test_int[:, i] = model.predict(X_test_int)\n",
    "\n",
    "meta_reg_int = LinearRegression().fit(meta_X_train_int, y_valid)\n",
    "joblib.dump(meta_reg_int, '../../fitted_models/meta_reg_int.pkl') # Dump fitted model to disk\n",
    "\n",
    "# Load fitted model to reproduce results\n",
    "meta_reg_int = joblib.load('../../fitted_models/meta_reg_int.pkl') \n",
    "print('-- Meta model 2: Linear Regression with main predictors & interaction terms --')\n",
    "print(\"Train R^2: {}\".format(meta_reg_int.score(meta_X_train_int, y_valid)))\n",
    "print(\"Test R^2: {}\".format(meta_reg_int.score(meta_X_test_int, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary\n",
    "$R^2$ score on the **test set** of all playlists:\n",
    "\n",
    "|          Model          | Main Only | Main & Interaction |\n",
    "|-------------------------|-----------|--------------------|\n",
    "| Linear Regression       | 0.25215   | 0.24658            |\n",
    "| PCA                     | N/A       | (n=188) 0.20381    |\n",
    "| RidgeCV                 | 0.25052   | 0.25243            |\n",
    "| LassoCV                 | 0.24915   | 0.26894            |\n",
    "| Random Forest           | 0.48157   | 0.47592            |\n",
    "| Adaboost                | 0.41946   | 0.41286            |\n",
    "| Meta - Weighted Avg     | 0.41066   | 0.41578            |\n",
    "| Meta - Linear Regression| 0.49653   | 0.49444            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAH+CAYAAABXxSI+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncXBtZmZmZtZDHFybmZmZmfWQ/wNkwmekocor9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c2b3550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the Test R^2 scores of all models\n",
    "model_names = ['Lin.Reg.', 'RidgeCV', 'LassoCV', 'RF', 'Adaboost', 'Meta 1\\nWeighted.Avg.', 'Meta 2\\nLin.Reg.']\n",
    "acc_test_main = [0.25215, 0.25052, 0.24915, 0.48157, 0.41946, 0.41066, 0.49653]\n",
    "acc_test_int = [0.24658, 0.25243, 0.26894, 0.47592, 0.41286, 0.41578, 0.49444]\n",
    "\n",
    "width = 0.3\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(np.arange(len(model_names)), acc_test_main, width, alpha=0.8, label='Main')\n",
    "plt.bar(np.arange(len(model_names))+width, acc_test_int, width, alpha=0.8, label='Main & Interaction')\n",
    "plt.xticks(np.arange(len(model_names))+0.5*width, model_names, fontsize=14)\n",
    "plt.title('Test $R^2$ VS. Models ', fontsize=20)\n",
    "plt.ylabel('Test $R^2$', fontsize=16)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
