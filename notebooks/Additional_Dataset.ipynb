{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combined an [additional dataset](https://www.kaggle.com/edumucelli/spotifys-worldwide-daily-song-ranking) of the 200 daily most streamed Spotify songs to our **tracks** database. Now each track has an additional field of **`score`**: Each time the track made the 200 most streamed list worldwide, its score is **increased by (201 - ranked position)**. The tracks in this additional dataset are matched with our scraped tracks by the trackIDs. Accordingly, each playlist now has an additional field of **`tracks_score`** to be the sum of all its tracks' `score` (0 if none of its tracks made to the 200 most streamed list ever).\n",
    "\n",
    "In this notebook, we first created a **track-score dictionary {key = trackID, value = score}**, updated this dictionary with our all tracks json database, and update all playlists to have a new field of `tracks_score`. The dataframe of processed playlists with `tracks_score` is saved to a local csv file `playlists_extra.csv`. \n",
    "\n",
    "We then fit the same set of regression models on 2 sets of features to predict the number of followers (log-scale) of each playlist. (The following process is almost the same as in Regression Models, except that we use the playlists with additional `tracks_score`.)\n",
    "\n",
    "- Feature set 1: **main predictors only**\n",
    "- Feature set 2: **main predictors and interaction terms of (genre X numerical_audio_feature_avg)**\n",
    "\n",
    "For each set of features, do the following 2 steps:\n",
    "- Use main predictors only and fit **single** regression models:\n",
    "    - Linear Regression\n",
    "    - (Perform PCA on the main predictors and interaction terms set of features)\n",
    "    - RidgeCV\n",
    "    - LassoCV\n",
    "    - Random Forest Regressor\n",
    "    - Adaboost Regressor\n",
    "\n",
    "- **Stack** all fitted models on the training set together to fit a\n",
    "    - **Meta regressor 1: Weighted Average ** \n",
    "        - Gather the predicted values of all the fitted single models on the validation set\n",
    "        - Average each single model's predicted value weighted by its accuracy on the same validation set\n",
    "    \n",
    "    - **Meta regressor 2: Meta Linear Regressor ** \n",
    "        - Gather the predicted values of all the fitted single models on the validation set\n",
    "        - Fit a linear regression model on these single models' predicted values\n",
    "\n",
    "As shown in the **summary** part at the end of this notebook, the addtional dataset **improved** test $R^2$ scores of the **Linear Regression model, RidgeCV, LassoCV** on both sets of features. 5-fold cross-validation of **PCA** on main predictors and the interaction terms selected out one more component (189) than before (188). This suggests the additional dataset did provide some useful information for better prediction of num_followers.\n",
    "\n",
    "However, test $R^2$ scores of the ensemble regressors (random forest and adaboost; and stacking meta models as a result) do not improve. This may be because the ensemble models' training process include random predictors selection and boostrapping, which already gained enough useful information without the additional dataset. Adding more predictors unnecessarily increased these models' complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "import collections\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save scraped data to json file\n",
    "def dump_data(data_to_json, file):\n",
    "    # example: file = '../data/playlists_5088.json'\n",
    "    with open(file,'w') as fd:\n",
    "        json.dump(data_to_json, fd)\n",
    "\n",
    "# Load json file\n",
    "def load_data(file):\n",
    "    with open(file, 'r') as fd:\n",
    "        data_from_json = json.load(fd)\n",
    "        return data_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def extract_track_features(tracks_db, playlists):\n",
    "    \"\"\"\n",
    "    Function to get track features and return a playlist dictionary with track features\n",
    "    \"\"\"\n",
    "    processed_playlists = deepcopy(playlists)\n",
    "    \n",
    "    missing_counts = 0\n",
    "    # Loop over each playlist\n",
    "    for index, playlist in enumerate(processed_playlists):\n",
    "        # get the list of track ids for each playlist\n",
    "        track_ids = playlist['track_ids']\n",
    "        track_feature_keys = ['acousticness', 'album_id', 'album_name', 'album_popularity','artists_genres', \n",
    "                              'artists_ids', 'artists_names', 'artists_num_followers', 'artists_popularities',\n",
    "                              'avg_artist_num_followers', 'avg_artist_popularity', 'danceability', 'duration_ms',\n",
    "                              'energy', 'explicit', 'instrumentalness', 'isrc', 'key', 'liveness', \n",
    "                              'loudness', 'mode', 'mode_artist_genre', 'name', 'num_available_markets',\n",
    "                              'popularity', 'speechiness', 'std_artist_num_followers', 'std_artist_popularity',\n",
    "                              'tempo', 'time_signature', 'valence']\n",
    "        \n",
    "        # new entries of audio features for each playlist as a list to append each track's audio feature\n",
    "        for track_feature_key in track_feature_keys:\n",
    "            playlist['track_' + track_feature_key] = []\n",
    "        \n",
    "        # append each tracks' audio features into the entries of the playlist\n",
    "        for track_id in track_ids:\n",
    "            # check if the track_id is in the scrapped_tracks\n",
    "            if track_id in tracks_db.keys():\n",
    "                # append each track's audio feature into the playlist dictionary\n",
    "                for track_feature_key in track_feature_keys:\n",
    "                    if track_feature_key in tracks_db[track_id].keys():\n",
    "                        playlist['track_' + track_feature_key].append(tracks_db[track_id][track_feature_key])\n",
    "            else:\n",
    "                missing_counts += 1\n",
    "        processed_playlists[index] = playlist\n",
    "    print('tracks that are missing : {}'.format(missing_counts))\n",
    "    return processed_playlists\n",
    "\n",
    "\n",
    "def build_playlist_dataframe_extra(playlists_dictionary_list):\n",
    "    \"\"\"\n",
    "    Function to build playlist dataframe from playlists dictionary with track features \n",
    "    PLUS TRACKS_SCORE\n",
    "    \"\"\"\n",
    "    if playlists_dictionary_list[7914]['id'] == '4krpfadGaaW42C7cEm2O0A':\n",
    "        del playlists_dictionary_list[7914]\n",
    "        \n",
    "    # features to take the avg and std\n",
    "    features_avg = ['track_acousticness', 'track_avg_artist_num_followers', 'track_album_popularity',\n",
    "                    'track_avg_artist_popularity', 'track_danceability', 'track_duration_ms', \n",
    "                    'track_energy', 'track_explicit', 'track_instrumentalness','track_liveness', \n",
    "                    'track_loudness', 'track_mode', 'track_num_available_markets',\n",
    "                    'track_std_artist_num_followers', 'track_std_artist_popularity',\n",
    "                    'track_popularity', 'track_speechiness', 'track_tempo', 'track_valence'\n",
    "                   ]                \n",
    "                      \n",
    "    # features to take the mode, # of uniques\n",
    "    features_mode = ['track_artists_genres','track_key','track_time_signature']\n",
    "\n",
    "    # features as is\n",
    "    features = ['collaborative', 'num_followers', 'num_tracks', 'tracks_score']\n",
    "\n",
    "    processed_playlists = {}\n",
    "\n",
    "    for index, playlist in enumerate(playlists_dictionary_list):\n",
    "        playlist_info = {} \n",
    "    #     playlist_info['id'] = playlist['id']\n",
    "\n",
    "        for key in playlist.keys():\n",
    "            if key in features_avg: # take avg and std\n",
    "                playlist_info[key + '_avg'] = np.mean(playlist[key])\n",
    "                playlist_info[key + '_std'] = np.std(playlist[key])\n",
    "                if key in set(['track_popularity', 'track_album_popularity', 'track_avg_artist_popularity']):\n",
    "                    playlist_info[key + '_max'] = max(playlist[key])\n",
    "            elif key in features_mode: # take mode\n",
    "                if playlist[key]:\n",
    "                    if key == 'track_artists_genres':\n",
    "                        flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "                        flattened_value = flatten(playlist[key])\n",
    "                        if flattened_value:\n",
    "                            counter = collections.Counter(flattened_value)\n",
    "                            playlist_info[key + '_mode'] = counter.most_common()[0][0]\n",
    "                            playlist_info[key + '_unique'] = len(set(flattened_value))\n",
    "                    else:\n",
    "                        counter = collections.Counter(playlist[key])\n",
    "                        playlist_info[key + '_mode'] = counter.most_common()[0][0]\n",
    "                        playlist_info[key + '_unique'] = len(set(playlist[key]))\n",
    "            elif key in features:\n",
    "                playlist_info[key] = playlist[key]\n",
    "\n",
    "        processed_playlists[index] = playlist_info\n",
    "    df = pd.DataFrame(processed_playlists).T\n",
    "    \n",
    "    # Drop all observations (playlists) with missingness\n",
    "    df_full = df.dropna(axis=0, how='any')\n",
    "    df_full.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Define our genre labels\n",
    "    predefined_genres =['pop rap', 'punk', 'korean pop', 'pop christmas', 'folk', 'indie pop', 'pop', \n",
    "                    'rock', 'rap' , 'house', 'indie', 'dance', 'edm', 'mellow', 'hip hop',  \n",
    "                    'alternative', 'jazz', 'r&b', 'soul', 'reggae', 'classical', 'funk', 'country',\n",
    "                    'metal', 'blues', 'elect']\n",
    "    # Create a new column genre_category\n",
    "    df_full['genre'] = None\n",
    "    \n",
    "    # Label genres\n",
    "    genres = df_full['track_artists_genres_mode']\n",
    "    for g in reversed(predefined_genres):\n",
    "        df_full['genre'][genres.str.contains(g)] = g\n",
    "\n",
    "    # Label all observations that did not match our predefined genres as 'other'  \n",
    "    df_full['genre'].fillna('other', inplace=True)\n",
    "    df_full.drop('track_artists_genres_mode', axis=1, inplace=True)\n",
    "    \n",
    "    return df_full\n",
    "\n",
    "\n",
    "def change_column_order(df, col_name, index): \n",
    "    \"\"\"\n",
    "    Function to change column order in a dataframe\n",
    "    \"\"\"\n",
    "    cols = df.columns.tolist() \n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Dataset Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build `score` field for each track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extra_df = pd.read_csv('../../data/extra_data.csv')\n",
    "\n",
    "# Build the filed of Score\n",
    "extra_df['Track_ID'] = extra_df.URL.str[31:]\n",
    "extra_df['Score'] = 201 - extra_df['Position']\n",
    "\n",
    "selected_cols = ['Track_ID', 'Score', 'Streams']\n",
    "extra_df = extra_df[selected_cols]\n",
    "\n",
    "# Drop missing values\n",
    "extra_df.dropna(axis=0, how='any', inplace=True)\n",
    "print('Is there any missing values in the extra dataset: {}'.format(extra_df.isnull().values.any()))\n",
    "\n",
    "# Save extra_df to csv file\n",
    "extra_df_grouped.reset_index(inplace=False)\n",
    "extra_df_grouped.to_csv('../../data/extra_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track_ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Streams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000xQL6tZNLJzIrtIgxqSl</td>\n",
       "      <td>388743</td>\n",
       "      <td>188175017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000xYdQfIZ4pDmBGzQalKU</td>\n",
       "      <td>11933</td>\n",
       "      <td>8432317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007d7JT41sSc1HqWTs4uw7</td>\n",
       "      <td>323</td>\n",
       "      <td>283424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>009Zz28Vgvnc5FvMXs6dEm</td>\n",
       "      <td>642</td>\n",
       "      <td>4955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009j4tQyJC53rmgTuXil9E</td>\n",
       "      <td>26</td>\n",
       "      <td>5234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Track_ID   Score    Streams\n",
       "0  000xQL6tZNLJzIrtIgxqSl  388743  188175017\n",
       "1  000xYdQfIZ4pDmBGzQalKU   11933    8432317\n",
       "2  007d7JT41sSc1HqWTs4uw7     323     283424\n",
       "3  009Zz28Vgvnc5FvMXs6dEm     642       4955\n",
       "4  009j4tQyJC53rmgTuXil9E      26       5234"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the extra dataframe\n",
    "extra_df = pd.read_csv('../../data/extra_df.csv')\n",
    "extra_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build  `tracks_score` field for each playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks_score_dict = dict(zip(list(extra_df['Track_ID']), list(extra_df['Score'])))\n",
    "\n",
    "# Load playlists\n",
    "playlists = load_data('../../data_archive/playlists_from_200_search_words.json')\n",
    "\n",
    "# Load tracks\n",
    "tracks_db = load_data('../../data_archive/tracks.json')\n",
    "\n",
    "# Add 'tracks_score' to each playlist dictionary\n",
    "for playlist in playlists:\n",
    "    tracks_score = 0\n",
    "    track_ids = playlist['track_ids']\n",
    "    for track_id in track_ids:\n",
    "        if track_id in tracks_score_dict:\n",
    "            tracks_score += tracks_score_dict[track_id]\n",
    "    playlist['tracks_score'] = tracks_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the playlist dataframe with the new `tracks_score` field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_playlists = extract_track_features(tracks_db, playlists)\n",
    "playlists_df_extra = build_playlist_dataframe_extra(processed_playlists)\n",
    "\n",
    "# Save the new dataframe of playlists\n",
    "playlists_df_extra.to_csv('../../data/playlists_extra.csv', index=False)\n",
    "\n",
    "# Load the new dataframe of playlists\n",
    "playlists_df_extra = pd.read_csv('../../data/playlists_extra.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression models with main predictors only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take **log transform** of the skewed response variable:\n",
    "\n",
    "**`num_followers` -> `log_num_followers`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log transformation\n",
    "playlists_df_extra['log_num_followers'] = np.log(list(playlists_df_extra['num_followers']+1))\n",
    "\n",
    "# Dropping the original num_followers, num_tracks\n",
    "playlists_df_extra.drop(['num_followers'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take **one-hot** encoding of the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>track_acousticness_avg</th>\n",
       "      <th>track_acousticness_std</th>\n",
       "      <th>track_album_popularity_avg</th>\n",
       "      <th>track_album_popularity_max</th>\n",
       "      <th>track_album_popularity_std</th>\n",
       "      <th>track_artists_genres_unique</th>\n",
       "      <th>track_avg_artist_num_followers_avg</th>\n",
       "      <th>track_avg_artist_num_followers_std</th>\n",
       "      <th>track_avg_artist_popularity_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>track_key_mode_3</th>\n",
       "      <th>track_key_mode_4</th>\n",
       "      <th>track_key_mode_5</th>\n",
       "      <th>track_key_mode_6</th>\n",
       "      <th>track_key_mode_7</th>\n",
       "      <th>track_key_mode_8</th>\n",
       "      <th>track_key_mode_9</th>\n",
       "      <th>track_key_mode_10</th>\n",
       "      <th>track_key_mode_11</th>\n",
       "      <th>log_num_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>0.180999</td>\n",
       "      <td>0.171120</td>\n",
       "      <td>71.673077</td>\n",
       "      <td>96</td>\n",
       "      <td>13.136445</td>\n",
       "      <td>60</td>\n",
       "      <td>1.276693e+06</td>\n",
       "      <td>1.320843e+06</td>\n",
       "      <td>82.256410</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.914325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>0.144201</td>\n",
       "      <td>0.160799</td>\n",
       "      <td>68.440000</td>\n",
       "      <td>100</td>\n",
       "      <td>15.511063</td>\n",
       "      <td>70</td>\n",
       "      <td>3.791621e+06</td>\n",
       "      <td>3.658858e+06</td>\n",
       "      <td>84.684000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.142412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.117615</td>\n",
       "      <td>72.421053</td>\n",
       "      <td>94</td>\n",
       "      <td>16.192317</td>\n",
       "      <td>44</td>\n",
       "      <td>2.319518e+06</td>\n",
       "      <td>2.237652e+06</td>\n",
       "      <td>86.705263</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.863271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.134162</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>57.025000</td>\n",
       "      <td>82</td>\n",
       "      <td>18.083815</td>\n",
       "      <td>97</td>\n",
       "      <td>2.387520e+06</td>\n",
       "      <td>3.589807e+06</td>\n",
       "      <td>72.987500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.146849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>0.171635</td>\n",
       "      <td>0.229736</td>\n",
       "      <td>53.461538</td>\n",
       "      <td>54</td>\n",
       "      <td>0.498519</td>\n",
       "      <td>5</td>\n",
       "      <td>8.566853e+04</td>\n",
       "      <td>2.347853e+05</td>\n",
       "      <td>55.059341</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.655859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_tracks  track_acousticness_avg  track_acousticness_std  \\\n",
       "0          52                0.180999                0.171120   \n",
       "1          75                0.144201                0.160799   \n",
       "2          38                0.116600                0.117615   \n",
       "3          40                0.134162                0.247197   \n",
       "4          26                0.171635                0.229736   \n",
       "\n",
       "   track_album_popularity_avg  track_album_popularity_max  \\\n",
       "0                   71.673077                          96   \n",
       "1                   68.440000                         100   \n",
       "2                   72.421053                          94   \n",
       "3                   57.025000                          82   \n",
       "4                   53.461538                          54   \n",
       "\n",
       "   track_album_popularity_std  track_artists_genres_unique  \\\n",
       "0                   13.136445                           60   \n",
       "1                   15.511063                           70   \n",
       "2                   16.192317                           44   \n",
       "3                   18.083815                           97   \n",
       "4                    0.498519                            5   \n",
       "\n",
       "   track_avg_artist_num_followers_avg  track_avg_artist_num_followers_std  \\\n",
       "0                        1.276693e+06                        1.320843e+06   \n",
       "1                        3.791621e+06                        3.658858e+06   \n",
       "2                        2.319518e+06                        2.237652e+06   \n",
       "3                        2.387520e+06                        3.589807e+06   \n",
       "4                        8.566853e+04                        2.347853e+05   \n",
       "\n",
       "   track_avg_artist_popularity_avg        ...          track_key_mode_3  \\\n",
       "0                        82.256410        ...                         0   \n",
       "1                        84.684000        ...                         0   \n",
       "2                        86.705263        ...                         0   \n",
       "3                        72.987500        ...                         0   \n",
       "4                        55.059341        ...                         0   \n",
       "\n",
       "   track_key_mode_4  track_key_mode_5  track_key_mode_6  track_key_mode_7  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 1                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   track_key_mode_8  track_key_mode_9  track_key_mode_10  track_key_mode_11  \\\n",
       "0                 0                 0                  0                  1   \n",
       "1                 0                 0                  0                  0   \n",
       "2                 0                 0                  0                  1   \n",
       "3                 0                 0                  0                  0   \n",
       "4                 0                 1                  0                  0   \n",
       "\n",
       "   log_num_followers  \n",
       "0          14.914325  \n",
       "1          11.142412  \n",
       "2          12.863271  \n",
       "3          11.146849  \n",
       "4           9.655859  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the useless varaible 'collaborative'\n",
    "playlists_df_extra.drop(['collaborative'], axis=1, inplace=True)\n",
    "categorical_predictors = ['genre', 'track_time_signature_mode', 'track_key_mode']\n",
    "numerical_predictors = list(set(playlists_df_extra.columns.values) - set(categorical_predictors))\n",
    "\n",
    "# One-hot encode categorical features\n",
    "playlists_df_extra = pd.get_dummies(playlists_df_extra, prefix = categorical_predictors, \n",
    "                                         columns = categorical_predictors, drop_first = True)\n",
    "\n",
    "# Reorder so that the response variable is the last column\n",
    "playlists_df_extra = change_column_order(playlists_df_extra, 'log_num_followers', len(playlists_df_extra.columns))\n",
    "\n",
    "playlists_df_extra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing values in our new dataset: False\n"
     ]
    }
   ],
   "source": [
    "print('Is there any missing values in our new dataset: {}'.format(playlists_df_extra.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data **6:1:1**\n",
    "1. **train set** for single models: 6/8 of all data\n",
    "2. **validation set** for single models & **train set for meta models**: 1/8 of all data\n",
    "3. **test set**: 1/8 of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(9001)\n",
    "msk1 = np.random.rand(len(playlists_df_extra)) < 0.75\n",
    "playlists_df_train_main = playlists_df_extra[msk1]\n",
    "playlists_df_nontrain_main = playlists_df_extra[~msk1]\n",
    "\n",
    "msk12 = np.random.rand(len(playlists_df_nontrain_main)) < 0.5\n",
    "playlists_df_valid_main = playlists_df_nontrain_main[msk12]\n",
    "playlists_df_test_main = playlists_df_nontrain_main[~msk12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7083, 86), (7083,), (1214, 86), (1214,), (1133, 86), (1133,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build predictors & response\n",
    "X_train_main = playlists_df_train_main.iloc[:,:-1]\n",
    "X_valid_main = playlists_df_valid_main.iloc[:,:-1]\n",
    "X_test_main = playlists_df_test_main.iloc[:,:-1]\n",
    "\n",
    "y_train = playlists_df_train_main['log_num_followers']\n",
    "y_valid = playlists_df_valid_main['log_num_followers']\n",
    "y_test = playlists_df_test_main['log_num_followers']\n",
    "\n",
    "X_train_main.shape, y_train.shape, X_valid_main.shape, y_valid.shape, X_test_main.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that have only 0 and **standardize** numerical variables using **train set's mean and std**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in X_train_main.columns:\n",
    "    if (X_train_main[col] == 0).all():\n",
    "        X_train_main.drop(col, axis=1, inplace=True)\n",
    "    else:\n",
    "        # Standardize a numerical variable\n",
    "        if not np.logical_or((X_train_main[col]==0), ((X_train_main[col]==1))).all():\n",
    "            mean_train = X_train_main[col].mean()\n",
    "            std_train = X_train_main[col].std()\n",
    "            X_train_main[col] = (X_train_main[col] - mean_train) / std_train\n",
    "            X_valid_main[col] = (X_valid_main[col] - mean_train) / std_train\n",
    "            X_test_main[col] = (X_test_main[col] - mean_train) / std_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit & Save model\n",
    "sim_lin_main = LinearRegression().fit(X_train_main, y_train)\n",
    "joblib.dump(sim_lin_main, '../../fitted_models_extra/sim_lin_main.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Linear Regression with all main predictors only --\n",
      "Training R^2:  0.274574920284\n",
      "Test R^2:  0.256241949862\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "sim_lin_main = joblib.load('../../fitted_models_extra/sim_lin_main.pkl') \n",
    "print('-- Linear Regression with all main predictors only --')\n",
    "print('Training R^2: ', sim_lin_main.score(X_train_main, y_train))\n",
    "print('Test R^2: ', sim_lin_main.score(X_test_main, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
    "ridge_cv_main = RidgeCV(alphas=lambdas, fit_intercept=True).fit(X_train_main, y_train)\n",
    "joblib.dump(ridge_cv_main, '../../fitted_models_extra/ridge_cv_main.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- RidgeCV (best alpha = 10.0) with all main predictors only --\n",
      "Training R^2: 0.274174747409772\n",
      "Test R^2: 0.25463769616193843\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model\n",
    "ridge_cv_main = joblib.load('../../fitted_models_extra/ridge_cv_main.pkl') \n",
    "ridge_r2_train_main = ridge_cv_main.score(X_train_main, y_train)\n",
    "ridge_r2_test_main = ridge_cv_main.score(X_test_main, y_test)\n",
    "\n",
    "print('-- RidgeCV (best alpha = {}) with all main predictors only --'.format(ridge_cv_main.alpha_))\n",
    "print(\"Training R^2: {}\".format(ridge_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(ridge_r2_test_main))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LassoCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
    "lasso_cv_main = LassoCV(alphas=lambdas, fit_intercept=True).fit(X_train_main, y_train)\n",
    "joblib.dump(lasso_cv_main, '../../fitted_models_extra/lasso_cv_main.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- LassoCV (best alpha = 0.01) with all main predictors only --\n",
      "Training R^2: 0.2668177814282259\n",
      "Test R^2: 0.2539347727528575\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model\n",
    "lasso_cv_main = joblib.load('../../fitted_models_extra/lasso_cv_main.pkl') \n",
    "lasso_r2_train_main = lasso_cv_main.score(X_train_main, y_train)\n",
    "lasso_r2_test_main = lasso_cv_main.score(X_test_main, y_test)\n",
    "\n",
    "print('-- LassoCV (best alpha = {}) with all main predictors only --'.format(lasso_cv_main.alpha_))\n",
    "print(\"Training R^2: {}\".format(lasso_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(lasso_r2_test_main))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([[4, 8, 16, 32, 64, 128, 256], [0.1, 0.3, 0.5, 0.7, 0.9]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_params = OrderedDict(\n",
    "    n_estimators = [2**(i+2) for i in np.arange(7)],\n",
    "    max_features = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    ")\n",
    "RF_params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use 5-fold validation to find the optimal n_estimators and max_features for Random Forest Regression\n",
    "cv_scores_RF_main = []\n",
    "params_dict_RF_main = {}\n",
    "\n",
    "for i, (n, f) in enumerate(product(*RF_params.values())):\n",
    "    params_dict_RF_main[i] = (n, f)\n",
    "    \n",
    "    # Cross Validation on Random Forest Classifier\n",
    "    RF_main = RandomForestRegressor(oob_score=False, n_estimators=n, max_features=f, n_jobs=-1, random_state=22)\n",
    "    scores = cross_val_score(RF_main, X_train_main, y_train, cv=5, scoring='r2')\n",
    "    cv_scores_RF_main.append(scores.mean())\n",
    "\n",
    "# Get the optimal set of parameters of the Random Forest Regressor\n",
    "idx_optimal = np.argmax(cv_scores_RF_main)\n",
    "optimal_params_RF_main = params_dict_RF_main[idx_optimal]\n",
    "print('-- Random Forest Regression with all main predictors only --')\n",
    "print('Maximum R^2 validation score = {}'.format(max(cv_scores_RF_main)))\n",
    "print('Optimal n_estimators = {}'.format(optimal_params_RF_main[0]))\n",
    "print('Optimal max_features = {}'.format(optimal_params_RF_main[1]))\n",
    "\n",
    "# Fit the best RF\n",
    "RF_best_main = RandomForestRegressor(oob_score=False, n_estimators=optimal_params_RF_main[0], \n",
    "                                     max_features=optimal_params_RF_main[1], n_jobs=-1, \n",
    "                                     random_state=22).fit(X_train_main, y_train)\n",
    "RF_best_r2_train_main = RF_best_main.score(X_train_main, y_train)\n",
    "RF_best_r2_test_main = RF_best_main.score(X_test_main, y_test)\n",
    "print('-- Best Random Forest Regression --')\n",
    "print(\"Training R^2: {}\".format(RF_best_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(RF_best_r2_test_main))\n",
    "\n",
    "# Dump fitted model to disk\n",
    "joblib.dump(RF_best_main, '../../fitted_models_extra/RF_best_main.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model to reproduce results directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best Random Forest Regression with all main predictors only --\n",
      "Training R^2: 0.9260804564458209\n",
      "Test R^2: 0.47225563755064515\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "RF_best_main = joblib.load('../../fitted_models_extra/RF_best_main.pkl') \n",
    "RF_best_r2_train_main = RF_best_main.score(X_train_main, y_train)\n",
    "RF_best_r2_test_main = RF_best_main.score(X_test_main, y_test)\n",
    "print('-- Best Random Forest Regression with all main predictors only --')\n",
    "print(\"Training R^2: {}\".format(RF_best_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(RF_best_r2_test_main))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([[2, 4, 6, 8], [4, 8, 16, 32, 64, 128, 256]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_params = OrderedDict(\n",
    "    base_depths = [2, 4, 6, 8],\n",
    "    n_estimators = [2**(i+2) for i in np.arange(7)]\n",
    ")\n",
    "ab_params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use 5-fold CV to choose max_depth & n_estimators in AdaBoost Regressor\n",
    "l_rate = 0.05\n",
    "params_dict_ab_main = {}\n",
    "cv_scores_ab_main = []\n",
    "for i, (d, n) in enumerate(product(*ab_params.values())):\n",
    "    params_dict_ab_main[i] = (d, n)\n",
    "    ab_main = AdaBoostRegressor(DecisionTreeRegressor(max_depth=d, random_state=22), n_estimators=n, \n",
    "                                learning_rate=l_rate, random_state=22)\n",
    "    scores = cross_val_score(ab_main, X_train_main, y_train, cv=5, scoring='r2')\n",
    "    cv_scores_ab_main.append(scores.mean())\n",
    "\n",
    "\n",
    "# Get the optimal set of parameters of the Random Forest Regressor\n",
    "idx_optimal = np.argmax(cv_scores_ab_main)\n",
    "optimal_params_ab_main = params_dict_ab_main[idx_optimal]\n",
    "print('-- AdaBoost Regression with all main predictors only --')\n",
    "print('Maximum R^2 cv score = {}'.format(max(cv_scores_ab_main)))\n",
    "print('Optimal base tree max_depth = {}'.format(optimal_params_ab_main[0]))\n",
    "print('Optimal n_estimators = {}'.format(optimal_params_ab_main[1]))\n",
    "\n",
    "# Fit the best Adaboost regressor\n",
    "ab_best_main = AdaBoostRegressor(DecisionTreeRegressor(max_depth=optimal_params_ab_main[0], random_state=22), \n",
    "                                 n_estimators=optimal_params_ab_main[1], learning_rate=l_rate, \n",
    "                                 random_state=22).fit(X_train_main, y_train)\n",
    "\n",
    "ab_best_r2_train_main = ab_best_main.score(X_train_main, y_train)\n",
    "ab_best_r2_test_main = ab_best_main.score(X_test_main, y_test)\n",
    "print('-- Best AdaBoost Regression --')\n",
    "print(\"Training R^2: {}\".format(ab_best_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(ab_best_r2_test_main))\n",
    "\n",
    "# Dump fitted model to disk\n",
    "joblib.dump(ab_best_main, '../../fitted_models_extra/ab_best_main.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model to reproduce results directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best AdaBoost Regression with all main predictors only --\n",
      "Training R^2: 0.6621121188291732\n",
      "Test R^2: 0.41227040525395264\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "ab_best_main = joblib.load('../../fitted_models_extra/ab_best_main.pkl') \n",
    "ab_best_r2_train_main = ab_best_main.score(X_train_main, y_train)\n",
    "ab_best_r2_test_main = ab_best_main.score(X_test_main, y_test)\n",
    "print('-- Best AdaBoost Regression with all main predictors only --')\n",
    "print(\"Training R^2: {}\".format(ab_best_r2_train_main))\n",
    "print(\"Test R^2: {}\".format(ab_best_r2_test_main))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Model: Weighted Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Meta model 1: Weighted Avg with all main predictors only --\n",
      "Valid (Meta Train) R^2: 0.40880273711359416\n",
      "Test R^2: 0.40446925924097\n"
     ]
    }
   ],
   "source": [
    "prefix = '../../fitted_models_extra/'\n",
    "suffix = '.pkl'\n",
    "models_main = ['sim_lin_main', 'ridge_cv_main', 'lasso_cv_main', 'RF_best_main', 'ab_best_main']\n",
    "\n",
    "# Record model's r2 score and predicted results on validation set\n",
    "weights_main = np.zeros((len(models_main),))\n",
    "preds_main_valid = np.zeros((y_valid.shape[0], len(models_main)))\n",
    "preds_main_test = np.zeros((y_test.shape[0], len(models_main)))\n",
    "for i, name in enumerate(models_main):\n",
    "    model_name = prefix + name + suffix\n",
    "    model = joblib.load(model_name) \n",
    "    weights_main[i] = model.score(X_valid_main, y_valid)\n",
    "    preds_main_valid[:, i] = model.predict(X_valid_main)\n",
    "    preds_main_test[:, i] = model.predict(X_test_main)\n",
    "\n",
    "weights_main = weights_main/np.sum(weights_main)\n",
    "meta_pred_main_valid = np.average(preds_main_valid, axis=1, weights=weights_main)\n",
    "meta_pred_main_test = np.average(preds_main_test, axis=1, weights=weights_main)\n",
    "\n",
    "meta_r2_valid_main = r2_score(y_valid, meta_pred_main_valid)\n",
    "meta_r2_test_main = r2_score(y_test, meta_pred_main_test)\n",
    "print('-- Meta model 1: Weighted Avg with all main predictors only --')\n",
    "print(\"Valid (Meta Train) R^2: {}\".format(meta_r2_valid_main))\n",
    "print(\"Test R^2: {}\".format(meta_r2_test_main))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Model: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Meta model 2: Linear Regression with all main predictors only --\n",
      "Train R^2: 0.4872242995695527\n",
      "Test R^2: 0.48532625439707866\n"
     ]
    }
   ],
   "source": [
    "# Record model's predicted results on validation set as the train set for the meta regressor\n",
    "meta_X_train_main = np.zeros((y_valid.shape[0], len(models_main)))\n",
    "meta_X_test_main = np.zeros((y_test.shape[0], len(models_main)))\n",
    "for i, name in enumerate(models_main):\n",
    "    model_name = prefix + name + suffix\n",
    "    model = joblib.load(model_name) \n",
    "    meta_X_train_main[:, i] = model.predict(X_valid_main)\n",
    "    meta_X_test_main[:, i] = model.predict(X_test_main)\n",
    "\n",
    "meta_reg_main = LinearRegression().fit(meta_X_train_main, y_valid)\n",
    "joblib.dump(meta_reg_main, '../../fitted_models_extra/meta_reg_main.pkl') # Dump fitted model to disk\n",
    "\n",
    "# Load fitted model to reproduce results\n",
    "meta_reg_main = joblib.load('../../fitted_models_extra/meta_reg_main.pkl') \n",
    "print('-- Meta model 2: Linear Regression with all main predictors only --')\n",
    "print(\"Train R^2: {}\".format(meta_reg_main.score(meta_X_train_main, y_valid)))\n",
    "print(\"Test R^2: {}\".format(meta_reg_main.score(meta_X_test_main, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression models with main predictors & interaction terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add interaction terms between **genres** and the **numerical audio features' average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_features_avg = ['track_acousticness_avg', 'track_album_popularity_avg', 'track_danceability_avg',\n",
    "                    'track_duration_ms_avg', 'track_energy_avg', 'track_explicit_avg', \n",
    "                    'track_instrumentalness_avg', 'track_liveness_avg', 'track_loudness_avg', 'track_mode_avg', \n",
    "                    'track_speechiness_avg', 'track_tempo_avg', 'track_valence_avg']\n",
    "genres = ['genre_blues', 'genre_classical', 'genre_country', 'genre_dance',\n",
    "       'genre_edm', 'genre_elect', 'genre_folk', 'genre_funk', 'genre_hip hop',\n",
    "       'genre_house', 'genre_indie', 'genre_indie pop', 'genre_jazz',\n",
    "       'genre_korean pop', 'genre_mellow', 'genre_metal', 'genre_other',\n",
    "       'genre_pop', 'genre_pop christmas', 'genre_pop rap', 'genre_punk',\n",
    "       'genre_r&b', 'genre_rap', 'genre_reggae', 'genre_rock', 'genre_soul',]\n",
    "\n",
    "cross_terms = audio_features_avg + genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>track_acousticness_avg</th>\n",
       "      <th>track_acousticness_std</th>\n",
       "      <th>track_album_popularity_avg</th>\n",
       "      <th>track_album_popularity_max</th>\n",
       "      <th>track_album_popularity_std</th>\n",
       "      <th>track_artists_genres_unique</th>\n",
       "      <th>track_avg_artist_num_followers_avg</th>\n",
       "      <th>track_avg_artist_num_followers_std</th>\n",
       "      <th>track_avg_artist_popularity_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>track_valence_avg_X_genre_pop</th>\n",
       "      <th>track_valence_avg_X_genre_pop christmas</th>\n",
       "      <th>track_valence_avg_X_genre_pop rap</th>\n",
       "      <th>track_valence_avg_X_genre_punk</th>\n",
       "      <th>track_valence_avg_X_genre_r&amp;b</th>\n",
       "      <th>track_valence_avg_X_genre_rap</th>\n",
       "      <th>track_valence_avg_X_genre_reggae</th>\n",
       "      <th>track_valence_avg_X_genre_rock</th>\n",
       "      <th>track_valence_avg_X_genre_soul</th>\n",
       "      <th>log_num_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>0.180999</td>\n",
       "      <td>0.171120</td>\n",
       "      <td>71.673077</td>\n",
       "      <td>96</td>\n",
       "      <td>13.136445</td>\n",
       "      <td>60</td>\n",
       "      <td>1.276693e+06</td>\n",
       "      <td>1.320843e+06</td>\n",
       "      <td>82.256410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.914325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>0.144201</td>\n",
       "      <td>0.160799</td>\n",
       "      <td>68.440000</td>\n",
       "      <td>100</td>\n",
       "      <td>15.511063</td>\n",
       "      <td>70</td>\n",
       "      <td>3.791621e+06</td>\n",
       "      <td>3.658858e+06</td>\n",
       "      <td>84.684000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.142412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.117615</td>\n",
       "      <td>72.421053</td>\n",
       "      <td>94</td>\n",
       "      <td>16.192317</td>\n",
       "      <td>44</td>\n",
       "      <td>2.319518e+06</td>\n",
       "      <td>2.237652e+06</td>\n",
       "      <td>86.705263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.863271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.134162</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>57.025000</td>\n",
       "      <td>82</td>\n",
       "      <td>18.083815</td>\n",
       "      <td>97</td>\n",
       "      <td>2.387520e+06</td>\n",
       "      <td>3.589807e+06</td>\n",
       "      <td>72.987500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.146849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>0.171635</td>\n",
       "      <td>0.229736</td>\n",
       "      <td>53.461538</td>\n",
       "      <td>54</td>\n",
       "      <td>0.498519</td>\n",
       "      <td>5</td>\n",
       "      <td>8.566853e+04</td>\n",
       "      <td>2.347853e+05</td>\n",
       "      <td>55.059341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.655859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 425 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_tracks  track_acousticness_avg  track_acousticness_std  \\\n",
       "0          52                0.180999                0.171120   \n",
       "1          75                0.144201                0.160799   \n",
       "2          38                0.116600                0.117615   \n",
       "3          40                0.134162                0.247197   \n",
       "4          26                0.171635                0.229736   \n",
       "\n",
       "   track_album_popularity_avg  track_album_popularity_max  \\\n",
       "0                   71.673077                          96   \n",
       "1                   68.440000                         100   \n",
       "2                   72.421053                          94   \n",
       "3                   57.025000                          82   \n",
       "4                   53.461538                          54   \n",
       "\n",
       "   track_album_popularity_std  track_artists_genres_unique  \\\n",
       "0                   13.136445                           60   \n",
       "1                   15.511063                           70   \n",
       "2                   16.192317                           44   \n",
       "3                   18.083815                           97   \n",
       "4                    0.498519                            5   \n",
       "\n",
       "   track_avg_artist_num_followers_avg  track_avg_artist_num_followers_std  \\\n",
       "0                        1.276693e+06                        1.320843e+06   \n",
       "1                        3.791621e+06                        3.658858e+06   \n",
       "2                        2.319518e+06                        2.237652e+06   \n",
       "3                        2.387520e+06                        3.589807e+06   \n",
       "4                        8.566853e+04                        2.347853e+05   \n",
       "\n",
       "   track_avg_artist_popularity_avg        ...          \\\n",
       "0                        82.256410        ...           \n",
       "1                        84.684000        ...           \n",
       "2                        86.705263        ...           \n",
       "3                        72.987500        ...           \n",
       "4                        55.059341        ...           \n",
       "\n",
       "   track_valence_avg_X_genre_pop  track_valence_avg_X_genre_pop christmas  \\\n",
       "0                       0.456071                                      0.0   \n",
       "1                       0.555027                                      0.0   \n",
       "2                       0.526526                                      0.0   \n",
       "3                       0.501825                                      0.0   \n",
       "4                       0.658846                                      0.0   \n",
       "\n",
       "   track_valence_avg_X_genre_pop rap  track_valence_avg_X_genre_punk  \\\n",
       "0                                0.0                             0.0   \n",
       "1                                0.0                             0.0   \n",
       "2                                0.0                             0.0   \n",
       "3                                0.0                             0.0   \n",
       "4                                0.0                             0.0   \n",
       "\n",
       "   track_valence_avg_X_genre_r&b  track_valence_avg_X_genre_rap  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                            0.0                            0.0   \n",
       "\n",
       "   track_valence_avg_X_genre_reggae  track_valence_avg_X_genre_rock  \\\n",
       "0                               0.0                             0.0   \n",
       "1                               0.0                             0.0   \n",
       "2                               0.0                             0.0   \n",
       "3                               0.0                             0.0   \n",
       "4                               0.0                             0.0   \n",
       "\n",
       "   track_valence_avg_X_genre_soul  log_num_followers  \n",
       "0                             0.0          14.914325  \n",
       "1                             0.0          11.142412  \n",
       "2                             0.0          12.863271  \n",
       "3                             0.0          11.146849  \n",
       "4                             0.0           9.655859  \n",
       "\n",
       "[5 rows x 425 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of the raw playlists dataframe with extra dataset info\n",
    "playlists_df_interaction = deepcopy(playlists_df_extra)\n",
    "\n",
    "# Generate 2-way interaction terms\n",
    "for feature in audio_features_avg:\n",
    "    for genre in genres:\n",
    "        playlists_df_interaction[feature+'_X_'+genre] = playlists_df_extra[feature] * playlists_df_extra[genre]\n",
    "\n",
    "playlists_df_interaction = change_column_order(playlists_df_interaction, 'log_num_followers', len(playlists_df_interaction.columns))\n",
    "playlists_df_interaction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data **6:1:1**\n",
    "1. **train set** for single models: 6/8 of all data\n",
    "2. **validation set** for single models & **train set for meta models**: 1/8 of all data\n",
    "3. **test set**: 1/8 of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into train & test set\n",
    "np.random.seed(9001)\n",
    "msk2 = np.random.rand(len(playlists_df_interaction)) < 0.75\n",
    "playlists_df_train_int = playlists_df_interaction[msk2]\n",
    "playlists_df_nontrain_int = playlists_df_interaction[~msk2]\n",
    "\n",
    "msk22 = np.random.rand(len(playlists_df_nontrain_int)) < 0.5\n",
    "playlists_df_valid_int = playlists_df_nontrain_int[msk22]\n",
    "playlists_df_test_int = playlists_df_nontrain_int[~msk22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7083, 424), (7083,), (1214, 424), (1214,), (1133, 424), (1133,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build predictors & response\n",
    "X_train_int = playlists_df_train_int.iloc[:,:-1]\n",
    "X_valid_int = playlists_df_valid_int.iloc[:,:-1]\n",
    "X_test_int = playlists_df_test_int.iloc[:,:-1]\n",
    "\n",
    "X_train_int.shape, y_train.shape, X_valid_int.shape, y_valid.shape, X_test_int.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that have only 0 and **standardize** numerical variables using **train set's mean and std**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in X_train_int.columns:\n",
    "    if (X_train_int[col] == 0).all():\n",
    "        X_train_int.drop(col, axis=1, inplace=True)\n",
    "    else:\n",
    "        # Standardize a numerical variable\n",
    "        if not np.logical_or((X_train_int[col]==0), ((X_train_int[col]==1))).all():\n",
    "            mean_train = X_train_int[col].mean()\n",
    "            std_train = X_train_int[col].std()\n",
    "            X_train_int[col] = (X_train_int[col] - mean_train) / std_train\n",
    "            X_valid_int[col] = (X_valid_int[col] - mean_train) / std_train\n",
    "            X_test_int[col] = (X_test_int[col] - mean_train) / std_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit & Save Model\n",
    "sim_lin_int = LinearRegression().fit(X_train_int, y_train)\n",
    "joblib.dump(sim_lin_int, '../../fitted_models_extra/sim_lin_int.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Linear Regression with main predictors and interaction terms --\n",
      "Training R^2:  0.334319723639\n",
      "Test R^2:  0.249699128912\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "sim_lin_int = joblib.load('../../fitted_models_extra/sim_lin_int.pkl') \n",
    "print('-- Linear Regression with main predictors and interaction terms --')\n",
    "print('Training R^2: ', sim_lin_int.score(X_train_int, y_train))\n",
    "print('Test R^2: ', sim_lin_int.score(X_test_int, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform PCA on main predictors & their interaction terms\n",
    "Use 5-Fold cross-validation to find the best n_components of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best n_components for PCA is 189\n"
     ]
    }
   ],
   "source": [
    "n_pca = 200\n",
    "r2_valid_cv = np.zeros((n_pca, 5))\n",
    "\n",
    "fold_ctr = 0\n",
    "for itrain, ivalid in KFold(n_splits=5, shuffle=True, random_state=9001).split(X_train_int.index):\n",
    "    # in general though its good for creating consistent psets, don't put seeds into kfold split\n",
    "    X_train_cv = X_train_int.iloc[itrain,:]\n",
    "    y_train_cv = y_train.iloc[itrain]\n",
    "    X_valid_cv = X_train_int.iloc[ivalid,:]\n",
    "    y_valid_cv = y_train.iloc[ivalid]\n",
    "    \n",
    "    # pca\n",
    "    pca = PCA()\n",
    "    pca.fit(X_train_cv)\n",
    "    X_train_pca_cv = pca.transform(X_train_cv)\n",
    "    X_valid_pca_cv = pca.transform(X_valid_cv)\n",
    "    \n",
    "    for comp in range(1, n_pca+1):\n",
    "        linear_cv = LinearRegression().fit(X_train_pca_cv[:,:comp], y_train_cv) # fit model\n",
    "        r2_valid_cv[comp-1,fold_ctr] = linear_cv.score(X_valid_pca_cv[:,:comp], y_valid_cv) # get valid r2 score\n",
    "        \n",
    "    fold_ctr += 1\n",
    "\n",
    "\n",
    "scores_valid = np.mean(r2_valid_cv, axis=1)[1:]\n",
    "best_n = np.argmax(scores_valid)\n",
    "print('The best n_components for PCA is {}'.format(best_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Linear Regression with main predictors and interaction terms best PCA(n_components=189) --\n",
      "Training R^2: 0.2743324728328148\n",
      "Test R^2: 0.20661172561646202\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train_int)\n",
    "\n",
    "X_train_int_pca_best = pca.transform(X_train_int)[:,:best_n]\n",
    "X_test_int_pca_best = pca.transform(X_test_int)[:,:best_n]\n",
    "\n",
    "linear_pca_best = LinearRegression().fit(X_train_int_pca_best, y_train)\n",
    "score_train_pca_best = linear_pca_best.score(X_train_int_pca_best, y_train)\n",
    "score_test_pca_best = linear_pca_best.score(X_test_int_pca_best, y_test)\n",
    "\n",
    "print('-- Linear Regression with main predictors and interaction terms best PCA(n_components={}) --'.format(best_n))\n",
    "print(\"Training R^2: {}\".format(score_train_pca_best))\n",
    "print(\"Test R^2: {}\".format(score_test_pca_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RidgeCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
    "ridge_cv_int = RidgeCV(alphas=lambdas, fit_intercept=True).fit(X_train_int, y_train)\n",
    "joblib.dump(ridge_cv_int, '../../fitted_models_extra/ridge_cv_int.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- RidgeCV (best alpha = 100.0) with main predictors and interaction terms --\n",
      "Training R^2: 0.30972349243028685\n",
      "Test R^2: 0.254361820516916\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model\n",
    "ridge_cv_int = joblib.load('../../fitted_models_extra/ridge_cv_int.pkl') \n",
    "ridge_r2_train_int = ridge_cv_int.score(X_train_int, y_train)\n",
    "ridge_r2_test_int = ridge_cv_int.score(X_test_int, y_test)\n",
    "\n",
    "print('-- RidgeCV (best alpha = {}) with main predictors and interaction terms --'.format(ridge_cv_int.alpha_))\n",
    "print(\"Training R^2: {}\".format(ridge_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(ridge_r2_test_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5]\n",
    "lasso_cv_int = LassoCV(alphas=lambdas, fit_intercept=True).fit(X_train_int, y_train)\n",
    "joblib.dump(lasso_cv_int, '../../fitted_models_extra/lasso_cv_int.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- LassoCV (best alpha = 0.01) with main predictors and interaction terms --\n",
      "Training R^2: 0.29734926714259624\n",
      "Test R^2: 0.27189212271615415\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model\n",
    "lasso_cv_int = joblib.load('../../fitted_models_extra/lasso_cv_int.pkl') \n",
    "lasso_r2_train_int = lasso_cv_int.score(X_train_int, y_train)\n",
    "lasso_r2_test_int = lasso_cv_int.score(X_test_int, y_test)\n",
    "\n",
    "print('-- LassoCV (best alpha = {}) with main predictors and interaction terms --'.format(lasso_cv_int.alpha_))\n",
    "print(\"Training R^2: {}\".format(lasso_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(lasso_r2_test_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use 5-fold CV to find the optimal n_estimators and max_features\n",
    "cv_scores_RF_int = []\n",
    "params_dict_RF_int = {}\n",
    "\n",
    "for i, (n, f) in enumerate(product(*RF_params.values())):\n",
    "    params_dict_RF_int[i] = (n, f)\n",
    "    \n",
    "    # Cross Validation on Random Forest Classifier\n",
    "    RF_int = RandomForestRegressor(oob_score=False, n_estimators=n, max_features=f, n_jobs=-1, random_state=22)\n",
    "    scores = cross_val_score(RF_int, X_train_main, y_train, cv=5, scoring='r2')\n",
    "    cv_scores_RF_int.append(scores.mean())\n",
    "\n",
    "# Get the optimal set of parameters of the Random Forest Regressor\n",
    "idx_optimal = np.argmax(cv_scores_RF_int)\n",
    "optimal_params_RF_int = params_dict_RF_int[idx_optimal]\n",
    "print('-- Random Forest Regression w/ interaction terms --')\n",
    "print('Maximum R^2 validation score = {}'.format(max(cv_scores_RF_int)))\n",
    "print('Optimal n_estimators = {}'.format(optimal_params_RF_int[0]))\n",
    "print('Optimal max_features = {}'.format(optimal_params_RF_int[1]))\n",
    "\n",
    "# Fit the best RF\n",
    "RF_best_int = RandomForestRegressor(oob_score=False, n_estimators=optimal_params_RF_int[0], \n",
    "                                     max_features=optimal_params_RF_int[1], n_jobs=-1, \n",
    "                                     random_state=22).fit(X_train_int, y_train)\n",
    "RF_best_r2_train_int = RF_best_int.score(X_train_int, y_train)\n",
    "RF_best_r2_test_int = RF_best_int.score(X_test_int, y_test)\n",
    "print('-- Best Random Forest Regression w/ interaction terms --')\n",
    "print(\"Training R^2: {}\".format(RF_best_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(RF_best_r2_test_int))\n",
    "\n",
    "# Dump fitted model to disk\n",
    "joblib.dump(RF_best_int, '../../fitted_models_extra/RF_best_int.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model to reproduce results directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best Random Forest Regression with main predictors and interaction terms --\n",
      "Training R^2: 0.9260684580091274\n",
      "Test R^2: 0.46526577792668766\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "RF_best_int = joblib.load('../../fitted_models_extra/RF_best_int.pkl') \n",
    "RF_best_r2_train_int = RF_best_int.score(X_train_int, y_train)\n",
    "RF_best_r2_test_int = RF_best_int.score(X_test_int, y_test)\n",
    "print('-- Best Random Forest Regression with main predictors and interaction terms --')\n",
    "print(\"Training R^2: {}\".format(RF_best_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(RF_best_r2_test_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use 5-fold CV to choose max_depth & n_estimators in AdaBoost Regressor\n",
    "l_rate = 0.05\n",
    "params_dict_ab_int = {}\n",
    "cv_scores_ab_int = []\n",
    "for i, (d, n) in enumerate(product(*ab_params.values())):\n",
    "    params_dict_ab_int[i] = (d, n)\n",
    "    ab_main = AdaBoostRegressor(DecisionTreeRegressor(max_depth=d, random_state=22), n_estimators=n, \n",
    "                                learning_rate=l_rate, random_state=22)\n",
    "    scores = cross_val_score(ab_main, X_train_int, y_train, cv=5, scoring='r2')\n",
    "    cv_scores_ab_int.append(scores.mean())\n",
    "\n",
    "# Get the optimal set of parameters of the AdaBoost Regressor\n",
    "idx_optimal = np.argmax(cv_scores_ab_int)\n",
    "optimal_params_ab_int = params_dict_ab_int[idx_optimal]\n",
    "print('-- AdaBoost Regression w/ interaction terms --')\n",
    "print('Maximum R^2 validation score = {}'.format(max(cv_scores_ab_int)))\n",
    "print('Optimal base tree max_depth = {}'.format(optimal_params_ab_int[0]))\n",
    "print('Optimal n_estimators = {}'.format(optimal_params_ab_int[1]))\n",
    "\n",
    "# Fit the best Adaboost regressor\n",
    "ab_best_int = AdaBoostRegressor(DecisionTreeRegressor(max_depth=optimal_params_ab_int[0], random_state=22), \n",
    "                                 n_estimators=optimal_params_ab_int[1], learning_rate=l_rate, \n",
    "                                 random_state=22).fit(X_train_int, y_train)\n",
    "\n",
    "ab_best_r2_train_int = ab_best_int.score(X_train_int, y_train)\n",
    "ab_best_r2_test_int = ab_best_int.score(X_test_int, y_test)\n",
    "print('-- Best AdaBoost Regression w/ interaction terms --')\n",
    "print(\"Training R^2: {}\".format(ab_best_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(ab_best_r2_test_int))\n",
    "\n",
    "# Dump fitted model to disk\n",
    "joblib.dump(ab_best_int, '../../fitted_models_extra/ab_best_int.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model to reproduce results directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best AdaBoost Regression with main predictors and interaction terms --\n",
      "Training R^2: 0.6447076537564405\n",
      "Test R^2: 0.4037085214338365\n"
     ]
    }
   ],
   "source": [
    "# Load fitted model to reproduce results\n",
    "ab_best_int = joblib.load('../../fitted_models_extra/ab_best_int.pkl') \n",
    "ab_best_r2_train_int = ab_best_int.score(X_train_int, y_train)\n",
    "ab_best_r2_test_int = ab_best_int.score(X_test_int, y_test)\n",
    "print('-- Best AdaBoost Regression with main predictors and interaction terms --')\n",
    "print(\"Training R^2: {}\".format(ab_best_r2_train_int))\n",
    "print(\"Test R^2: {}\".format(ab_best_r2_test_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Model: Weighted Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Meta model 1: Weighted Avg with main predictors and interaction terms --\n",
      "Valid (Meta Train) R^2: 0.4075419472481713\n",
      "Test R^2: 0.4079655803159107\n"
     ]
    }
   ],
   "source": [
    "prefix = '../../fitted_models_extra/'\n",
    "suffix = '.pkl'\n",
    "models_int = ['sim_lin_int', 'ridge_cv_int', 'lasso_cv_int', 'RF_best_int', 'ab_best_int']\n",
    "\n",
    "# Record model's r2 score and predicted results on validation set\n",
    "weights_int = np.zeros((len(models_int),))\n",
    "preds_int_valid = np.zeros((y_valid.shape[0], len(models_int)))\n",
    "preds_int_test = np.zeros((y_test.shape[0], len(models_int)))\n",
    "for i, name in enumerate(models_int):\n",
    "    model_name = prefix + name + suffix\n",
    "    model = joblib.load(model_name) \n",
    "    weights_int[i] = model.score(X_valid_int, y_valid)\n",
    "    preds_int_valid[:, i] = model.predict(X_valid_int)\n",
    "    preds_int_test[:, i] = model.predict(X_test_int)\n",
    "\n",
    "weights_int = weights_int/np.sum(weights_int)\n",
    "meta_pred_int_valid = np.average(preds_int_valid, axis=1, weights=weights_int)\n",
    "meta_pred_int_test = np.average(preds_int_test, axis=1, weights=weights_int)\n",
    "\n",
    "meta_r2_valid_int = r2_score(y_valid, meta_pred_int_valid)\n",
    "meta_r2_test_int = r2_score(y_test, meta_pred_int_test)\n",
    "print('-- Meta model 1: Weighted Avg with main predictors and interaction terms --')\n",
    "print(\"Valid (Meta Train) R^2: {}\".format(meta_r2_valid_int))\n",
    "print(\"Test R^2: {}\".format(meta_r2_test_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Model: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Meta model 2: Linear Regression Stacking with main predictors and interaction terms --\n",
      "Train R^2: 0.4858998651056701\n",
      "Test R^2: 0.483405689121045\n"
     ]
    }
   ],
   "source": [
    "# Record model's predicted results on validation set as the train set for the meta regressor\n",
    "meta_X_train_int = np.zeros((y_valid.shape[0], len(models_int)))\n",
    "meta_X_test_int = np.zeros((y_test.shape[0], len(models_int)))\n",
    "for i, name in enumerate(models_int):\n",
    "    model_name = prefix + name + suffix\n",
    "    model = joblib.load(model_name) \n",
    "    meta_X_train_int[:, i] = model.predict(X_valid_int)\n",
    "    meta_X_test_int[:, i] = model.predict(X_test_int)\n",
    "\n",
    "meta_reg_int = LinearRegression().fit(meta_X_train_int, y_valid)\n",
    "joblib.dump(meta_reg_int, '../../fitted_models_extra/meta_reg_int.pkl') # Dump fitted model to disk\n",
    "\n",
    "# Load fitted model to reproduce results\n",
    "meta_reg_int = joblib.load('../../fitted_models_extra/meta_reg_int.pkl') \n",
    "print('-- Meta model 2: Linear Regression Stacking with main predictors and interaction terms --')\n",
    "print(\"Train R^2: {}\".format(meta_reg_int.score(meta_X_train_int, y_valid)))\n",
    "print(\"Test R^2: {}\".format(meta_reg_int.score(meta_X_test_int, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary\n",
    "$R^2$ score on the new **test set** of all playlists with the extra field of `tracks_score`:\n",
    "\n",
    "|          Model          | Main Only | Main & Interaction |\n",
    "|-------------------------|-----------|--------------------|\n",
    "| Linear Regression       | 0.25624   | 0.24970            |\n",
    "| PCA                     | N/A       | (n=189) 0.20661    |\n",
    "| RidgeCV                 | 0.25464   | 0.25436            |\n",
    "| LassoCV                 | 0.25393   | 0.27189            |\n",
    "| Random Forest           | 0.47226   | 0.46527            |\n",
    "| Adaboost                | 0.41227   | 0.40371            |\n",
    "| Meta - Weighted Avg     | 0.40447   | 0.40797            |\n",
    "| Meta - Linear Regression| 0.48533   | 0.48341            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAH+CAYAAABXxSI+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1166d6588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the Test R^2 scores of all models\n",
    "model_names = ['Lin.Reg.', 'RidgeCV', 'LassoCV', 'RF', 'Adaboost', 'Meta 1\\nWeighted.Avg.', 'Meta 2\\nLin.Reg.']\n",
    "acc_test_main = [0.25624, 0.25464, 0.25393, 0.47226, 0.41227, 0.40447, 0.48533]\n",
    "acc_test_int = [0.24970, 0.25436, 0.27189, 0.46527, 0.40371, 0.40797, 0.48341]\n",
    "\n",
    "width = 0.3\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(np.arange(len(model_names)), acc_test_main, width, alpha=0.8, label='Main')\n",
    "plt.bar(np.arange(len(model_names))+width, acc_test_int, width, alpha=0.8, label='Main & Interaction')\n",
    "plt.xticks(np.arange(len(model_names))+0.5*width, model_names, fontsize=14)\n",
    "plt.title('Test $R^2$ w/ Additional Data VS. Models ', fontsize=20)\n",
    "plt.ylabel('Test $R^2$', fontsize=16)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
