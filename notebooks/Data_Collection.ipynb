{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection from the Spotify API\n",
    "Here, we document our process to collect data from the Spotify API. \n",
    "\n",
    "A brief overview of the steps: \n",
    "\n",
    "- Get authentication token for accessing the API\n",
    "- Sample Spotify playlists \n",
    "\n",
    "    - Specify 150 predefined search keywords \n",
    "    - Use random word generator to generate 50 random words\n",
    "    - Combine the 2 lists and use get_playlists_by_search_word() to get playlists that match the search words\n",
    "    - For each keyword, scrape 50 playlists on Spotify that match\n",
    " \n",
    "- Store playlist sample with associated attributes in a json file. Attributes include:\n",
    "    - Playlist ID\n",
    "    - Owner ID\n",
    "    - Whether playlist is collaborative\n",
    "    - Number of tracks\n",
    "    - Track IDs\n",
    "    - Number of follower\n",
    "- Get track info from the sample of playlists. Information include:\n",
    "    - Track name\n",
    "    - Track ID\n",
    "    - Track ISRC ID\n",
    "    - Artist names\n",
    "    - Artist IDs\n",
    "    - Artist genres\n",
    "    - Artist popularities\n",
    "    - Artist number of followers\n",
    "    - Album name\n",
    "    - Album ID\n",
    "    - Album popularity\n",
    "    - Audio features ('danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature')\n",
    "    - Whether lyrics is explicit\n",
    "    - Number of available markets\n",
    "    - Popularity\n",
    "- Store all track information in a tracks.json file\n",
    "Note: A track is often associated with multiple artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions\n",
    "These libraries and functions are used to scrape the Spotify API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from random_words import RandomWords\n",
    "import spotipy\n",
    "from spotipy.client import Spotify\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_auth_spotipy () -> Spotify:\n",
    "    \"\"\"\n",
    "    Function that returns authorized Spotify client\n",
    "    \"\"\" \n",
    "    os.environ['SPOTIPY_CLIENT_ID'] = 'c4cd8ee33b624ca6b224debdef35ba58'\n",
    "    os.environ['SPOTIPY_CLIENT_SECRET'] = '3d5127677713483d99ded163e45198c6'\n",
    "\n",
    "    client_credentials_manager = SpotifyClientCredentials()\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "    return sp\n",
    "\n",
    "\n",
    "def dump_data(data_to_json, file):\n",
    "    \"\"\"\n",
    "    Function to save scraped data to json file\n",
    "    example: file = '../data/playlists_5088.json'\n",
    "    \"\"\"\n",
    "    with open(file,'w') as fd:\n",
    "        json.dump(data_to_json, fd)\n",
    "\n",
    "\n",
    "def load_data(file):\n",
    "    \"\"\"\n",
    "    Function to load json file\n",
    "    \"\"\"\n",
    "    with open(file, 'r') as fd:\n",
    "        data_from_json = json.load(fd)\n",
    "        return data_from_json\n",
    "\n",
    "\n",
    "def generate_search_word(predefined, number):\n",
    "    \"\"\"\n",
    "    Funciton to generate a list of search words, including a set of predefined words and randomly generated words\n",
    "    \"\"\"\n",
    "    rw = RandomWords()\n",
    "    random_words = rw.random_words(letter=None, count=number)\n",
    "    search_words = predefined + random_words\n",
    "    return list(set(search_words))\n",
    "\n",
    "\n",
    "def get_playlists_by_search_word(search_words):\n",
    "    \"\"\"\n",
    "    Function to get playlists from the Spotify API using a list of search words\n",
    "    \"\"\"\n",
    "    all_playlists = []\n",
    "\n",
    "    for word in search_words:\n",
    "    #     time.sleep(1)\n",
    "        try:\n",
    "            print(word)\n",
    "            playlists = sp.search(word, type='playlist', limit=50)\n",
    "\n",
    "            for i, playlist in enumerate(playlists['playlists']['items']):\n",
    "                playlist_info = {}\n",
    "                user = playlist['owner']['id']\n",
    "\n",
    "                try:\n",
    "                    current_playlist = sp.user_playlist(user, playlist_id=playlist['id'])\n",
    "\n",
    "                    tracks = current_playlist['tracks']['items']\n",
    "                    track_ids = set()\n",
    "                    for track in tracks:\n",
    "                        if track['track']:\n",
    "                            track_ids.add(track['track']['id'])\n",
    "\n",
    "                    playlist_info['track_ids'] = list(track_ids) # convert the set of track_ids of a playlist into a list\n",
    "\n",
    "                    playlist_info['num_followers'] = current_playlist['followers']['total']\n",
    "                    playlist_info['collaborative'] = current_playlist['collaborative']\n",
    "                    playlist_info['id'] = current_playlist['id']\n",
    "                    playlist_info['owner_id'] = current_playlist['owner']['id']\n",
    "                    playlist_info['num_tracks'] = current_playlist['tracks']['total']\n",
    "\n",
    "                    all_playlists.append(playlist_info)\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return all_playlists\n",
    "\n",
    "\n",
    "def get_tracks_in_playlists(playlists):\n",
    "    \"\"\"\n",
    "    Function to extract track features from a list of playlists\n",
    "    \"\"\"\n",
    "    all_tracks = {}\n",
    "    track_ids_set = set()\n",
    "    len_playlists = len(playlists)\n",
    "    for i, playlist in enumerate(playlists):\n",
    "        sys.stdout.write('\\r{0}% completed.'.format((float(i+1)/len_playlists)*100))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        track_ids = playlist['track_ids']\n",
    "        track_ids = [i for i in track_ids if i] # remove NaNs in track_ids\n",
    "\n",
    "        for track_id in track_ids:\n",
    "            try:\n",
    "                if track_id in track_ids_set:\n",
    "                    continue\n",
    "                track_ids_set.add(track_id)\n",
    "                track_info = {}\n",
    "\n",
    "                # Features related to the TRACK itself\n",
    "                track = sp.track(track_id)\n",
    "                track_info['id'] = track_id\n",
    "                track_info['name'] = track['name']\n",
    "                \n",
    "                if 'explicit' in track:\n",
    "                    track_info['explicit'] = track['explicit']\n",
    "                if track['external_ids']:\n",
    "                    track_info['isrc'] = track['external_ids']['isrc']\n",
    "                \n",
    "                track_info['num_available_markets'] = len(track['available_markets'])\n",
    "\n",
    "                # Get audio_features of a track\n",
    "                audio_feature_keys = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "                                     'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature']\n",
    "                track_audio_feature = sp.audio_features(track_id)[0]\n",
    "                if track_audio_feature:\n",
    "                    for key in audio_feature_keys:\n",
    "                        track_info[key] = track_audio_feature[key]\n",
    "                track_info['popularity'] = track['popularity']\n",
    "                \n",
    "                \n",
    "                # Features related to the ALBUM\n",
    "                album = sp.album(track['album']['id'])\n",
    "                track_info['album_name'] = album['name']\n",
    "                track_info['album_id'] = album['id']\n",
    "                track_info['album_genres'] = album['genres']\n",
    "                track_info['album_popularity'] = album['popularity']\n",
    "                \n",
    "                # Features related to the ARTIST\n",
    "                track_info['artists_names'] = []\n",
    "                track_info['artists_ids'] = []\n",
    "                track_info['artists_popularities'] = []\n",
    "                track_info['artists_num_followers'] = []\n",
    "                track_info['artists_genres'] = []\n",
    "                \n",
    "                for artist in track['artists']:\n",
    "                    current_artist = sp.artist(artist['id'])\n",
    "                    track_info['artists_names'].append(current_artist['name'])\n",
    "                    track_info['artists_ids'].append(current_artist['id'])\n",
    "                    track_info['artists_popularities'].append(current_artist['popularity'])\n",
    "                    track_info['artists_num_followers'].append(current_artist['followers']['total'])\n",
    "                    track_info['artists_genres'].extend(current_artist['genres'])\n",
    "                \n",
    "                \n",
    "                track_info['avg_artist_popularity'] = np.mean(track_info['artists_popularities'])\n",
    "                track_info['std_artist_popularity'] = np.std(track_info['artists_popularities'])\n",
    "                track_info['avg_artist_num_followers'] = np.mean(track_info['artists_num_followers'])\n",
    "                track_info['std_artist_num_followers'] = np.std(track_info['artists_num_followers'])\n",
    "                \n",
    "                if (track_info['artists_genres']):\n",
    "                    # count the most freqent artist genre\n",
    "\n",
    "                    counter = collections.Counter(track_info['artists_genres'])\n",
    "                    track_info['mode_artist_genre'] = counter.most_common()[0][0]\n",
    "                \n",
    "                all_tracks[track_id] = track_info\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "    return all_tracks  \n",
    "\n",
    "\n",
    "def missing_tracks(tracks_db, playlists):\n",
    "    \"\"\"\n",
    "    Function that checks if tracks in playlists are missing from tracks database(tracks_db)\n",
    "    Returns a set of missing track ids \n",
    "    \"\"\"\n",
    "    missing_counts = 0\n",
    "    missing_tracks = []\n",
    "    # Loop over each playlist\n",
    "    for index, playlist in enumerate(playlists):\n",
    "        # get the list of track ids for playlist\n",
    "        track_ids = playlist['track_ids']\n",
    "        \n",
    "        # check if tracks in playlist are in the track database\n",
    "        for track_id in track_ids:\n",
    "            # check if the track_id is in the tracks_db\n",
    "            if track_id in tracks_db.keys():\n",
    "                continue\n",
    "            else:\n",
    "                missing_counts += 1\n",
    "                missing_tracks.append(track_id)\n",
    "    print('tracks that are missing : {}'.format(missing_counts))\n",
    "    return set(missing_tracks)\n",
    "\n",
    "\n",
    "def get_tracks_by_track_ids(track_ids):\n",
    "    \"\"\"\n",
    "    Function to extract track features from a list of track ids\n",
    "    \"\"\"\n",
    "    all_tracks = {}\n",
    "    num_track_ids = len(track_ids)\n",
    "    for i, track_id in enumerate(track_ids):\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            sys.stdout.write('\\r{0}% completed.'.format((float(i+1)/num_track_ids)*100))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            track_info = {}\n",
    "\n",
    "            # Features related to the TRACK itself\n",
    "            track = sp.track(track_id)\n",
    "            track_info['id'] = track_id\n",
    "            track_info['name'] = track['name']\n",
    "\n",
    "            if 'explicit' in track:\n",
    "                track_info['explicit'] = track['explicit']\n",
    "            if track['external_ids']:\n",
    "                track_info['isrc'] = track['external_ids']['isrc']\n",
    "\n",
    "            track_info['num_available_markets'] = len(track['available_markets'])\n",
    "\n",
    "            # Get audio_features of a track\n",
    "            audio_feature_keys = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "                                 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature']\n",
    "            track_audio_feature = sp.audio_features(track_id)[0]\n",
    "            if track_audio_feature:\n",
    "                for key in audio_feature_keys:\n",
    "                    track_info[key] = track_audio_feature[key]\n",
    "            track_info['popularity'] = track['popularity']\n",
    "\n",
    "\n",
    "            # Features related to the ALBUM\n",
    "            album = sp.album(track['album']['id'])\n",
    "            track_info['album_name'] = album['name']\n",
    "            track_info['album_id'] = album['id']\n",
    "            track_info['album_genres'] = album['genres']\n",
    "            track_info['album_popularity'] = album['popularity']\n",
    "\n",
    "            # Features related to the ARTIST\n",
    "            track_info['artists_names'] = []\n",
    "            track_info['artists_ids'] = []\n",
    "            track_info['artists_popularities'] = []\n",
    "            track_info['artists_num_followers'] = []\n",
    "            track_info['artists_genres'] = []\n",
    "\n",
    "            for artist in track['artists']:\n",
    "                current_artist = sp.artist(artist['id'])\n",
    "                track_info['artists_names'].append(current_artist['name'])\n",
    "                track_info['artists_ids'].append(current_artist['id'])\n",
    "                track_info['artists_popularities'].append(current_artist['popularity'])\n",
    "                track_info['artists_num_followers'].append(current_artist['followers']['total'])\n",
    "                track_info['artists_genres'].extend(current_artist['genres'])\n",
    "\n",
    "            track_info['avg_artist_popularity'] = np.mean(track_info['artists_popularities'])\n",
    "            track_info['std_artist_popularity'] = np.std(track_info['artists_popularities'])\n",
    "            track_info['avg_artist_num_followers'] = np.mean(track_info['artists_num_followers'])\n",
    "            track_info['std_artist_num_followers'] = np.std(track_info['artists_num_followers'])\n",
    "\n",
    "            if (track_info['artists_genres']):\n",
    "                # count the most freqent artist genre\n",
    "                counter = collections.Counter(track_info['artists_genres'])\n",
    "                track_info['mode_artist_genre'] = counter.most_common()[0][0]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        all_tracks[track_id] = track_info\n",
    "            \n",
    "    return all_tracks  \n",
    "\n",
    "# initialize spotify authentication token\n",
    "sp = get_auth_spotipy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define search queries (search words)\n",
    "To broadly and randomly sample playlists from the Spotify API, we combine 150 predefined words and 50 randomly generated words as our search words to query the API. \n",
    "\n",
    "Our 150 predefined search words are mostly inspired from https://insights.spotify.com/us/2015/12/18/trending-playlist-words-2015/, https://www.digitaltrends.com/music/best-playlists-on-spotify/2/, and https://gizmodo.com/these-are-the-25-most-popular-spotify-playlists-510275721."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify 150 predefined search words\n",
    "predefined = ['your', 'my', 'are', 'the', 'is', 'a', 'can', 'love', 'hate', 'holiday', 'work', 'workday',\n",
    "              'weekend', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'beautiful',\n",
    "              'fall', 'summer', 'spring', 'winter', 'classics',  'throwback', 'car', 'morning', 'shower', 'current', \n",
    "              'jesus', 'party', 'gym','late', 'night', 'old', 'chill', 'country', 'new', 'feel', 'good', 'workout', \n",
    "              'slow','hood','tropical', 'EDM', 'wedding', 'sex', 'honeymoon', 'senior', 'cool', 'house', 'jam',\n",
    "              'today', 'top', 'hits', 'dance', 'mix', 'teen', 'cardio', 'hangouts', 'hot', 'ultimate',\n",
    "              'hip hop', 'mega', 'upbeat', 'acoustic', 'deep', 'girls', 'baby', 'indie', 'punk', 'rock', 'family',\n",
    "              'funk', 'jazz', 'instrumental', 'rap', 'beats', 'future', 'happy', 'emotional', 'great', 'magic',\n",
    "              'finds', 'escape', 'fresh', 'high', 'low', 'buzz', 'kill', 'mood', 'blue' 'dirty', 'soul', 'pop',\n",
    "              'beach', 'dream', 'shuffle', 'date', 'romantic', 'prom', 'college', 'kids', 'sleep', 'serenade',\n",
    "              'calm', 'light', 'heavy', 'soft', 'strong', 'drama', 'confession', 'blink', 'sad', 'heart',\n",
    "              'trend', 'trending', 'max', 'folk', 'blues', 'contemporary', 'electric', 'R&B', 'alternative', \n",
    "              'easy', 'metal', 'reggae', 'southern', 'cozy', 'darling', 'like', 'you', 'I', 'club', 'mind', \n",
    "              'waltz', 'glow', 'crazy', 'women', 'men', 'vibes', 'wave', 'trip', 'crave', 'him', 'break', \n",
    "              'true', 'different', 'her']\n",
    "\n",
    "# Generate 200 search words combining 150 predefined and 50 random words\n",
    "search_words = generate_search_word(predefined=predefined, number=50)\n",
    "\n",
    "# Save search words (keywords) to json\n",
    "dump_data(search_words, '../data/200_search_words.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Spotify API \n",
    "With these search words, we scrape the Spotify API for playlists that match these search queries. For each of the search words, we scraped 50 matched playlists. Therefore, with 200 search words, we scraped 9511 unique playlists. We save the matched playlists in a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load keywords\n",
    "keywords = load_data('../data/200_search_words.json')\n",
    "\n",
    "# Scrape the Spotify API for playlists that match these keywords\n",
    "all_playlists = get_playlists_by_search_word(keywords)\n",
    "\n",
    "# Save playlists to json\n",
    "dump_data(all_playlists, '../data/playlists_from_200_search_words.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we scrape the songs that are associated with these playlists. We only get the unique songs (i.e. if 2 playlists have the same song, we only scrape the song once). Note: because it takes a very long time to scrape, we  divided the list of playlists into 5 sections and scraped them in parallel. These json files containing track information are merged into a single track database at the conclusion of our data collection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all playlists\n",
    "all_playlists = load_data('../data/playlists_from_200_search_words.json')\n",
    "\n",
    "# Scrape track information from Spotify in playlists\n",
    "tracks_2000 = get_tracks_in_playlists(all_playlists[:2000])\n",
    "tracks_4000 = get_tracks_in_playlists(all_playlists[2000:4000])\n",
    "tracks_6000 = get_tracks_in_playlists(all_playlists[4000:6000])\n",
    "tracks_8000 = get_tracks_in_playlists(all_playlists[6000:8000])\n",
    "tracks_9000 = get_tracks_in_playlists(all_playlists[8000:9000])\n",
    "tracks_last = get_tracks_in_playlists(all_playlists[9000:])\n",
    "\n",
    "# Save track inforamtion to json\n",
    "dump_data(tracks_2000, '../data/tracks_2000.json')\n",
    "dump_data(tracks_4000, '../data/tracks_2000_4000.json')\n",
    "dump_data(tracks_6000, '../data/tracks_4000_6000.json')\n",
    "dump_data(tracks_8000, '../data/tracks_6000_8000.json')\n",
    "dump_data(tracks_9000, '../data/tracks_8000_9000.json')\n",
    "dump_data(tracks_last, '../data/tracks_last.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first scrape, we checked to see if we have missing tracks in our database. For those tracks that are missing, we re-scraped the Spotify API based on their track IDs and store all track data into our tracks.json database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all track databases\n",
    "tracks = {}\n",
    "tracks_2000 = load_data('../data_archive/tracks_2000.json')\n",
    "tracks_4000 = load_data('../data_archive/tracks_2000_4000.json')\n",
    "tracks_6000 = load_data('../data_archive/tracks_4000_6000.json')\n",
    "tracks_8000 = load_data('../data_archive/tracks_6000_8000.json')\n",
    "tracks_9000 = load_data('../data_archive/tracks_8000_9000.json')\n",
    "tracks_last = load_data('../data_archive/tracks_9000.json')\n",
    "\n",
    "# Merge track dictionaries\n",
    "tracks.update(tracks_2000)\n",
    "tracks.update(tracks_4000)\n",
    "tracks.update(tracks_6000)\n",
    "tracks.update(tracks_8000)\n",
    "tracks.update(tracks_9000)\n",
    "tracks.update(tracks_last)\n",
    "\n",
    "# Find missing tracks in the playlists\n",
    "missing_2000 = missing_tracks(tracks_2000, all_playlists[1000:2000])\n",
    "missing_4000 = missing_tracks(tracks_4000, all_playlists[2000:4000])\n",
    "missing_6000 = missing_tracks(tracks_6000, all_playlists[4000:6000])\n",
    "missing_8000 = missing_tracks(tracks_8000, all_playlists[6000:8000])\n",
    "missing_9000 = missing_tracks(tracks_9000, all_playlists[8000:9000])\n",
    "missing_last = missing_tracks(tracks_last, all_playlists[9000:])\n",
    "\n",
    "# Re-scrape the API for the missing tracks\n",
    "missing_tracks_2000 = get_tracks_by_track_ids(missing_2000)\n",
    "missing_tracks_4000 = get_tracks_by_track_ids(missing_4000)\n",
    "missing_tracks_6000 = get_tracks_by_track_ids(missing_6000)\n",
    "missing_tracks_8000 = get_tracks_by_track_ids(missing_8000)\n",
    "missing_tracks_9000 = get_tracks_by_track_ids(missing_9000)\n",
    "missing_tracks_last = get_tracks_by_track_ids(missing_last)\n",
    "\n",
    "# Merge re-scraped track dictionaries\n",
    "tracks.update(missing_tracks_2000)\n",
    "tracks.update(missing_tracks_4000)\n",
    "tracks.update(missing_tracks_6000)\n",
    "tracks.update(missing_tracks_8000)\n",
    "tracks.update(missing_tracks_9000)\n",
    "tracks.update(missing_tracks_last)\n",
    "\n",
    "# Save the merged dictionaries as a single json file\n",
    "dump_data(tracks, '../data_archive/tracks.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check one last time to confirm that there is no missing tracks from the playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks that are missing : 505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_playlists = load_data('../data_archive/playlists_from_200_search_words.json')\n",
    "tracks_db = load_data('../data_archive/tracks.json')\n",
    "missing_tracks(tracks_db, all_playlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: While there are still 505 tracks missing, these are entries without track IDs. We will discard these entries in subsequent data preprocessing step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
